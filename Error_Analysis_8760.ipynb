{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis on 8760 profiles (22 profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output files are written out in parent directory: C:\\Users\\tgoforth\\Documents\\IPM temporal resolution project\\outputs\\error_analysis\n"
     ]
    }
   ],
   "source": [
    "#importing packages needed for analysis\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from pandas import DataFrame\n",
    "\n",
    "path = os.getcwd()\n",
    "#print(path)\n",
    "\n",
    "#this code creates an output directory in the parent director, if one does not exist yet\n",
    "#Note: this is where all of the output files will be written, since outputs are large this saves space in git\n",
    "path = os.getcwd()\n",
    "parent = os.path.dirname(path)\n",
    "outputs_dir = parent+'\\outputs\\error_analysis'\n",
    "if not os.path.exists(outputs_dir):\n",
    "    os.makedirs(outputs_dir)\n",
    "print('output files are written out in parent directory: '+outputs_dir)\n",
    "\n",
    "##UNCOMMENT WHICH PROFILE BEING ANALYZED \n",
    "x = 'load'\n",
    "x2 = 'Load'\n",
    "\n",
    "#x = 'solar'\n",
    "#x2 = 'Solar_Gen'\n",
    "\n",
    "#x = 'wind'\n",
    "#x2 = 'Wind_Gen'\n",
    "\n",
    "profiles = ['norm','timeofday','bind_1hr','seq_2hr','seq_4hr','seq_8hr','seq_12hr','seq_24hr','seq_48hr',\n",
    "           'seq_120hr','bind_8760hr','1dt_mon_24hr','1dt_mon_4hr','1dt_sea_24hr','2dt_mon_24hr','2dt_sea_24hr',\n",
    "            '2dt_bim_4hr','2dt_sea_4hr','2dt_sgp_4hr','3dt_mon_24hr','3dt_sea_24hr','3dt_ann_24hr','3dt_bim_4hr',\n",
    "            '3dt_sgp_4hr','3dt_sea_4hr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DFs for error analysis\n",
    "# DF to use for regional error analysis, like RMSE and number of representative hours \n",
    "regions = pd.read_csv('../outputs/load_long_format.csv')\n",
    "regions = regions['Region'].unique()\n",
    "regions = pd.DataFrame(regions).rename(columns={0:'Region'})\n",
    "#print(regions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop and create error files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rep_hours = regions\n",
    "reg_RMSE = regions\n",
    "prof_RMSE = {}\n",
    "\n",
    "for i in range(len(profiles)):\n",
    "    segments = pd.read_csv('../outputs/'+x+'/'+x+'_segments_'+profiles[i]+'.csv')\n",
    "    hours = pd.read_csv('../outputs/'+x+'/'+x+'_8760_'+profiles[i]+'.csv')\n",
    "    \n",
    "    # use groupby region to count number of representative hours in each region\n",
    "    aggregations = {'Avg':'count'}\n",
    "    stat1 = segments.groupby(['Region'],as_index=False).agg(aggregations)\n",
    "    stat1 = stat1.rename(columns={'Avg': profiles[i]})\n",
    "    \n",
    "    rep_hours = pd.merge(rep_hours, stat1, on='Region', how='left')\n",
    "    \n",
    "    # calculate RMSE \n",
    "    stat2 = hours[['Region','R_Group','Hour_Tot',x2,'Avg']].copy()\n",
    "    \n",
    "    # export differences to CSV\n",
    "    stat2['Diff'] = stat2[x2] - stat2['Avg'] \n",
    "    stat2.to_csv('../outputs/error_analysis/'+x+'_'+profiles[i]+'_diff.csv')\n",
    "    \n",
    "    # regional RMSE\n",
    "    stat3 = stat2.copy()\n",
    "    stat3['Square'] = stat3['Diff']**2\n",
    "    stat_reg = stat3.groupby('Region',as_index=False).agg({'Square' : sum})\n",
    "    stat_reg = stat_reg.rename(columns={'Square':'Square_Sum'})\n",
    "    stat_reg['Mean'] = stat_reg['Square_Sum'] / 8760 \n",
    "    stat_reg[profiles[i]] = stat_reg['Mean']**(1/2)\n",
    "    stat_reg = stat_reg.drop(columns={'Square_Sum','Mean'})\n",
    "\n",
    "    reg_RMSE = pd.merge(reg_RMSE, stat_reg, on='Region', how='left')\n",
    "    \n",
    "    # profile RMSE\n",
    "    stat4 = stat2.copy()\n",
    "    stat4 = stat4.rename(columns={'Square':'RMSE'})\n",
    "    stat4['RMSE'] = stat2['Diff']**2\n",
    "    stat4 = stat4.agg({'RMSE' : sum})\n",
    "    stat4 = stat4 / 551880 \n",
    "    stat4[profiles[i]] = stat4**(1/2)\n",
    "    stat4[profiles[i]] = stat4[profiles[i]].values\n",
    "\n",
    "    prof_RMSE.update({profiles[i] : (stat4[profiles[i]])})\n",
    "    \n",
    "rep_hours.to_csv('../outputs/error_analysis/rep_hours_summary.csv')\n",
    "reg_RMSE.to_csv('../outputs/error_analysis/regional_RMSE.csv')\n",
    "profile_df = pd.DataFrame.from_dict(prof_RMSE,orient='index').rename(columns={0:'RMSE'})\n",
    "profile_df.to_csv('../outputs/error_analysis/profile_RMSE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
