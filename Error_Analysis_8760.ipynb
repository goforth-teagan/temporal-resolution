{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis on 8760 profiles (22 profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output files are written out in parent directory: C:\\Users\\tgoforth\\Documents\\IPM temporal resolution project\\outputs\\error_analysis\n"
     ]
    }
   ],
   "source": [
    "#importing packages needed for analysis\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from pandas import DataFrame\n",
    "\n",
    "path = os.getcwd()\n",
    "#print(path)\n",
    "\n",
    "#this code creates an output directory in the parent director, if one does not exist yet\n",
    "#Note: this is where all of the output files will be written, since outputs are large this saves space in git\n",
    "path = os.getcwd()\n",
    "parent = os.path.dirname(path)\n",
    "outputs_dir = parent+'\\outputs\\error_analysis'\n",
    "if not os.path.exists(outputs_dir):\n",
    "    os.makedirs(outputs_dir)\n",
    "print('output files are written out in parent directory: '+outputs_dir)\n",
    "\n",
    "##UNCOMMENT WHICH PROFILE BEING ANALYZED \n",
    "x = 'load'\n",
    "x2 = 'Load'\n",
    "\n",
    "#x = 'solar'\n",
    "#x2 = 'Solar_Gen'\n",
    "\n",
    "#x = 'wind'\n",
    "#x2 = 'Wind_Gen'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "difference in values \n",
    "root mean square for each region\n",
    "other analyses? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in data \n",
    "## Choose the profile to use by commenting / uncommenting code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### GENERAL DATA LOAD ###############\n",
    "# have to manually input CSV file name if not one of the 22 profiles\n",
    "#x_segments = pd.read_csv('')\n",
    "#x_hours = pd.read_csv('')\n",
    "#x_name = ''\n",
    "\n",
    "############### IPM APPROACH (2 profiles) ###############\n",
    "# NORM\n",
    "#x_segments = pd.read_csv('../outputs/'+x+'/'+x+'_segments_NORM.csv')\n",
    "#x_hours = pd.read_csv('../outputs/'+x+'/'+x+'_8760_NORM.csv')\n",
    "#x_name = 'norm'\n",
    "\n",
    "# TOD before group\n",
    "#x_segments = pd.read_csv('../outputs/'+x+'/'+x+'_segments_timeofday.csv')\n",
    "#x_hours = pd.read_csv('../outputs/'+x+'/'+x+'_8760_timeofday.csv')\n",
    "#x_name = 'timeofday'\n",
    "\n",
    "############### SEQUENTIAL APPROACH (7 profiles) ###############\n",
    "# 2-hr\n",
    "#x_segments = pd.read_csv('../outputs/'+x+'/'+x+'_segments_seq_2hr.csv')\n",
    "#x_hours = pd.read_csv('../outputs/'+x+'/'+x+'_8760_seq_2hr.csv')\n",
    "#x_name = 'seq_2hr'\n",
    "\n",
    "# 4-hr\n",
    "#x_segments = pd.read_csv('../outputs/'+x+'/'+x+'_segments_seq_4hr.csv')\n",
    "#x_hours = pd.read_csv('../outputs/'+x+'/'+x+'_8760_seq_4hr.csv')\n",
    "#x_name = 'seq_4hr'\n",
    "\n",
    "# 8-hr\n",
    "#x_segments = pd.read_csv('../outputs/'+x+'/'+x+'_segments_seq_8hr.csv')\n",
    "#x_hours = pd.read_csv('../outputs/'+x+'/'+x+'_8760_seq_8hr.csv')\n",
    "#x_name = 'seq_8hr'\n",
    "\n",
    "# 12-hr\n",
    "#x_segments = pd.read_csv('../outputs/'+x+'/'+x+'_segments_seq_12hr.csv')\n",
    "#x_hours = pd.read_csv('../outputs/'+x+'/'+x+'_8760_seq_12hr.csv')\n",
    "#x_name = 'seq_12hr'\n",
    "\n",
    "# 24-hr\n",
    "#x_segments = pd.read_csv('../outputs/'+x+'/'+x+'_segments_seq_24hr.csv')\n",
    "#x_hours = pd.read_csv('../outputs/'+x+'/'+x+'_8760_seq_24hr.csv')\n",
    "#x_name = 'seq_24hr'\n",
    "\n",
    "# 48-hr\n",
    "#x_segments = pd.read_csv('../outputs/'+x+'/'+x+'_segments_seq_48hr.csv')\n",
    "#x_hours = pd.read_csv('../outputs/'+x+'/'+x+'_8760_seq_48hr.csv')\n",
    "#x_name = 'seq_48hr'\n",
    "\n",
    "# 120-hr\n",
    "#x_segments = pd.read_csv('../outputs/'+x+'/'+x+'_segments_seq_120hr.csv')\n",
    "#x_hours = pd.read_csv('../outputs/'+x+'/'+x+'_8760_seq_120hr.csv')\n",
    "#x_name = 'seq_120hr'\n",
    "\n",
    "############### ONE/TWO DAY APPROACH (7 profiles) ###############\n",
    "# One day type, monthly, 24 hrs\n",
    "#x_segments = pd.read_csv('../outputs/'+x+'/'+x+'_segments_1daytype_monthly_24hr.csv')\n",
    "#x_hours = pd.read_csv('../outputs/'+x+'/'+x+'_8760_1daytype_monthly_24hr.csv')\n",
    "#x_name = '1daytype_month_24hr'\n",
    "\n",
    "# One day type, season, 24 hrs\n",
    "#x_segments = pd.read_csv('../outputs/'+x+'/'+x+'_segments_1daytype_season_24hr.csv')\n",
    "#x_hours = pd.read_csv('../outputs/'+x+'/'+x+'_8760_1daytype_season_24hr.csv')\n",
    "#x_name = '1daytype_season_24hr'\n",
    "\n",
    "# Two day type, monthly, 24 hrs\n",
    "#x_segments = pd.read_csv('../outputs/'+x+'/'+x+'_segments_2daytype_monthly_24hr.csv')\n",
    "#x_hours = pd.read_csv('../outputs/'+x+'/'+x+'_8760_2daytype_monthly_24hr.csv')\n",
    "#x_name = '2daytype_month_24hr'\n",
    "\n",
    "# Two day type, season, 24 hrs#\n",
    "#x_segments = pd.read_csv('../outputs/'+x+'/'+x+'_segments_2daytype_season_24hr.csv')\n",
    "#x_hours = pd.read_csv('../outputs/'+x+'/'+x+'_8760_2daytype_season_24hr.csv')\n",
    "#x_name = '2daytype_season_24hr'\n",
    "\n",
    "# Two day type, monthly, 4 hrs\n",
    "#x_segments = pd.read_csv('../outputs/'+x+'/'+x+'_segments_2daytype_month_4hr.csv')\n",
    "#x_hours = pd.read_csv('../outputs/'+x+'/'+x+'_8760_2daytype_month_4hr.csv')\n",
    "#x_name = '2daytype_month_4hr'\n",
    "\n",
    "# Two day type, bimonthly, 4 hrs\n",
    "#x_segments = pd.read_csv('../outputs/'+x+'/'+x+'_segments_2daytype_bimonth_4hr.csv')\n",
    "#x_hours = pd.read_csv('../outputs/'+x+'/'+x+'_8760_2daytype_bimonth_4hr.csv')\n",
    "#x_name = '2daytype_bimonth_4hr'\n",
    "\n",
    "# Two day type, season, 4 hrs\n",
    "#x_segments = pd.read_csv('../outputs/'+x+'/'+x+'_segments_2daytype_season_4hr.csv')\n",
    "#x_hours = pd.read_csv('../outputs/'+x+'/'+x+'_8760_2daytype_season_4hr.csv')\n",
    "#x_name = '2daytype_season_4hr'\n",
    "\n",
    "############### THREE DAY TYPE APPROACH (6 profiles) ###############\n",
    "# Three day type, monthly, 24 hrs\n",
    "#x_segments = pd.read_csv('../outputs/'+x+'/'+x+'_segments_3daytype_monthly_24hr.csv')\n",
    "#x_hours = pd.read_csv('../outputs/'+x+'/'+x+'_8760_3daytype_monthly_24hr.csv')\n",
    "#x_name = '3daytype_month_24hr'\n",
    "\n",
    "# Three day type, season, 24 hrs\n",
    "#x_segments = pd.read_csv('../outputs/'+x+'/'+x+'_segments_3daytype_season_24hr.csv')\n",
    "#x_hours = pd.read_csv('../outputs/'+x+'/'+x+'_8760_3daytype_season_24hr.csv')\n",
    "#x_name = '3daytype_season_24hr'\n",
    "\n",
    "# Three day type, annual, 24 hrs\n",
    "#x_segments = pd.read_csv('../outputs/'+x+'/'+x+'_segments_3daytype_annual_24hr.csv')\n",
    "#x_hours = pd.read_csv('../outputs/'+x+'/'+x+'_8760_3daytype_annual_24hr.csv')\n",
    "#x_name = '3daytype_annual_24hr'\n",
    "\n",
    "# Three day type, bimonthly, 4 hrs\n",
    "#x_segments = pd.read_csv('../outputs/'+x+'/'+x+'_segments_3daytype_bimonth_4hr.csv')\n",
    "#x_hours = pd.read_csv('../outputs/'+x+'/'+x+'_8760_3daytype_bimonth_4hr.csv')\n",
    "#x_name = '3daytype_bimonth_4hr'\n",
    "\n",
    "# Three day type, season based, 4 hrs\n",
    "#x_segments = pd.read_csv('../outputs/'+x+'/'+x+'_segments_3daytype_seasonbased_4hr.csv')\n",
    "#x_hours = pd.read_csv('../outputs/'+x+'/'+x+'_8760_3daytype_seasonbased_4hr.csv')\n",
    "#x_name = '3daytype_seasonbased_4hr'\n",
    "\n",
    "# Three day type, season, 4 hrs\n",
    "x_segments = pd.read_csv('../outputs/'+x+'/'+x+'_segments_3daytype_season_4hr.csv')\n",
    "x_hours = pd.read_csv('../outputs/'+x+'/'+x+'_8760_3daytype_season_4hr.csv')\n",
    "x_name = '3daytype_season_4hr'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create outputs: total number of representative hours, RMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Region  Rep_Count\n",
      "0   ERC_REST         54\n",
      "1   ERC_WEST         54\n",
      "2       FRCC         54\n",
      "3   MIS_AMSO         54\n",
      "4     MIS_AR         54\n",
      "..       ...        ...\n",
      "58   WECC_WY         54\n",
      "59  WEC_BANC         54\n",
      "60  WEC_CALN         54\n",
      "61  WEC_LADW         54\n",
      "62  WEC_SDGE         54\n",
      "\n",
      "[63 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#print(x_hours)\n",
    "\n",
    "# use groupby region to count number of representative hours in each region\n",
    "aggregations = {'Avg':'count'}\n",
    "stat1 = x_segments.groupby(['Region'],as_index=False).agg(aggregations)\n",
    "stat1 = stat1.rename(columns={'Avg':'Rep_Count'})\n",
    "#stat1 = stat1[['Region','Count']].copy()\n",
    "\n",
    "print(stat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Region           Avg  Hour_Tot    Square_Sum          Mean  \\\n",
      "0     ERC_REST  29443.558559       111  4.067633e+08  3.664535e+06   \n",
      "1     ERC_REST  29796.642659       361  1.622126e+09  4.493425e+06   \n",
      "2     ERC_REST  32400.546218       119  1.664162e+09  1.398456e+07   \n",
      "3     ERC_REST  32597.629139       151  1.629911e+09  1.079411e+07   \n",
      "4     ERC_REST  33159.873362       229  3.582208e+09  1.564283e+07   \n",
      "...        ...           ...       ...           ...           ...   \n",
      "3397  WEC_SDGE   3093.250000        16  1.305863e+06  8.161644e+04   \n",
      "3398  WEC_SDGE   3145.583333        12  4.659269e+05  3.882724e+04   \n",
      "3399  WEC_SDGE   3184.750000        20  3.922880e+06  1.961440e+05   \n",
      "3400  WEC_SDGE   3582.200000        20  5.263615e+06  2.631808e+05   \n",
      "3401  WEC_SDGE   3701.300000        20  5.218936e+06  2.609468e+05   \n",
      "\n",
      "             RMSE  \n",
      "0     1914.297419  \n",
      "1     2119.770006  \n",
      "2     3739.593398  \n",
      "3     3285.439791  \n",
      "4     3955.101522  \n",
      "...           ...  \n",
      "3397   285.685907  \n",
      "3398   197.046297  \n",
      "3399   442.881460  \n",
      "3400   513.011462  \n",
      "3401   510.829531  \n",
      "\n",
      "[3402 rows x 6 columns]\n",
      "          Region R_Group  Rep_Count  Hour_Tot   Load           Avg  \\\n",
      "0       ERC_REST     ERC         54       111  26989  29443.558559   \n",
      "1       ERC_REST     ERC         54       361  27006  29796.642659   \n",
      "2       ERC_REST     ERC         54       361  27025  29796.642659   \n",
      "3       ERC_REST     ERC         54       361  27059  29796.642659   \n",
      "4       ERC_REST     ERC         54       361  27069  29796.642659   \n",
      "...          ...     ...        ...       ...    ...           ...   \n",
      "551875  WEC_SDGE     WEC         54       186   4434   2900.677419   \n",
      "551876  WEC_SDGE     WEC         54        20   4446   3701.300000   \n",
      "551877  WEC_SDGE     WEC         54        20   4465   3582.200000   \n",
      "551878  WEC_SDGE     WEC         54        20   4470   3701.300000   \n",
      "551879  WEC_SDGE     WEC         54        20   4479   3701.300000   \n",
      "\n",
      "               Diff        Square    Square_Sum          Mean         RMSE  \n",
      "0      -2454.558559  6.024858e+06  4.067633e+08  3.664535e+06  1914.297419  \n",
      "1      -2790.642659  7.787686e+06  1.622126e+09  4.493425e+06  2119.770006  \n",
      "2      -2771.642659  7.682003e+06  1.622126e+09  4.493425e+06  2119.770006  \n",
      "3      -2737.642659  7.494687e+06  1.622126e+09  4.493425e+06  2119.770006  \n",
      "4      -2727.642659  7.440034e+06  1.622126e+09  4.493425e+06  2119.770006  \n",
      "...             ...           ...           ...           ...          ...  \n",
      "551875  1533.322581  2.351078e+06  2.942980e+07  1.582247e+05   397.774729  \n",
      "551876   744.700000  5.545781e+05  5.218936e+06  2.609468e+05   510.829531  \n",
      "551877   882.800000  7.793358e+05  5.263615e+06  2.631808e+05   513.011462  \n",
      "551878   768.700000  5.908997e+05  5.218936e+06  2.609468e+05   510.829531  \n",
      "551879   777.700000  6.048173e+05  5.218936e+06  2.609468e+05   510.829531  \n",
      "\n",
      "[551880 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# calculate RMSE \n",
    "stat2 = x_hours[['Region','R_Group','Hour_Tot',x2,'Avg']].copy()\n",
    "stat2 = pd.merge(stat2,stat1,on='Region',how='left')\n",
    "stat2 = stat2[['Region','R_Group','Rep_Count','Hour_Tot',x2,'Avg']]\n",
    "\n",
    "#print(stat2)\n",
    "\n",
    "stat2['Diff'] = stat2[x2] - stat2['Avg'] \n",
    "stat2['Square'] = stat2['Diff']**2\n",
    "stat_reg = stat2.groupby(['Region','Avg','Hour_Tot'],as_index=False).agg({'Square' : sum})\n",
    "stat_reg = stat_reg.rename(columns = {'Square':'Square_Sum'}) \n",
    "stat_reg['Mean'] = stat_reg['Square_Sum'] / stat_reg['Hour_Tot'] \n",
    "stat_reg['RMSE'] = stat_reg['Mean']**(1/2)\n",
    "print(stat_reg)\n",
    "\n",
    "stat2 = pd.merge(stat2,stat_reg,on=['Region','Avg','Hour_Tot'],how='left')\n",
    "print(stat2)\n",
    "\n",
    "stat2.to_csv('../outputs/error_analysis/'+x+'_'+x_name+'_error.csv')\n",
    "stat_reg.to_csv('../outputs/error_analysis/'+x+'_'+x_name+'region_error.csv')\n",
    "\n",
    "# RMSE tells us how spread out the data is over a line of best fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5.518800e+05\n",
       "mean    -4.323028e-12\n",
       "std      1.277079e+03\n",
       "min     -1.923308e+04\n",
       "25%     -2.518426e+02\n",
       "50%     -5.064452e+00\n",
       "75%      2.379612e+02\n",
       "max      1.975285e+04\n",
       "Name: Diff, dtype: float64"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# descriptive statistics of entire data set \n",
    "stat2['Diff'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows in dataset for testing = 8760\n",
      "count    8.760000e+03\n",
      "mean    -2.493511e-11\n",
      "std      3.048958e+03\n",
      "min     -1.143375e+04\n",
      "25%     -1.917797e+03\n",
      "50%     -1.611372e+02\n",
      "75%      1.803554e+03\n",
      "max      1.975285e+04\n",
      "Name: Diff, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# descriptive statistics of only a single region\n",
    "x_FRCC = stat2[stat2['R_Group']=='FRCC']\n",
    "print('number of rows in dataset for testing =',x_FRCC.shape[0])\n",
    "\n",
    "x_FRCC_stat = x_FRCC['Diff'].describe()\n",
    "print(x_FRCC_stat)\n",
    "\n",
    "\n",
    "## TO DO: create DF of all stats for all 22 profiles ###\n",
    "x_FRCC_stat.to_csv('../outputs/error_analysis/'+x+'_'+x_name+'_FRCC_stat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
