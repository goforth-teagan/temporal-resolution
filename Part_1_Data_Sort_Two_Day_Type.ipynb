{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Date and Day of Week columns in the DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           2016        2011\n",
      "0    2016-01-01  2011-01-01\n",
      "1    2016-01-02  2011-01-02\n",
      "2    2016-01-03  2011-01-03\n",
      "3    2016-01-04  2011-01-04\n",
      "4    2016-01-05  2011-01-05\n",
      "..          ...         ...\n",
      "360  2016-12-26  2011-12-27\n",
      "361  2016-12-27  2011-12-28\n",
      "362  2016-12-28  2011-12-29\n",
      "363  2016-12-29  2011-12-30\n",
      "364  2016-12-30  2011-12-31\n",
      "\n",
      "[365 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#importing packages needed for analysis\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from pandas import DataFrame\n",
    "\n",
    "path = os.getcwd()\n",
    "#print(path)\n",
    "\n",
    "load_dur1 = pd.read_csv('outputs/load_long_format.csv', index_col=0)\n",
    "load_years = pd.read_csv('inputs/load_years.csv').dropna()\n",
    "#print(load_dur1.head())\n",
    "print(load_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "\n",
    "#repeat the date for 24 times for each hour in the day\n",
    "year_2016 = load_years['2016'].repeat(24).reset_index(drop=True)\n",
    "year_2011 = load_years['2011'].repeat(24).reset_index(drop=True)\n",
    "#print(year_2016)\n",
    "\n",
    "#use itertools.cycle to make the date repeat until it reaches the end of the dataframe\n",
    "year_2016 = cycle(year_2016)\n",
    "year_2011 = cycle(year_2011)\n",
    "\n",
    "#create temporary data frames where they will iterate through. Needed to achieve the correct length of the DF\n",
    "temp2016 = load_dur1.loc[load_dur1['R_Group'] == 'ERC'].copy()\n",
    "temp2011 = load_dur1.loc[load_dur1['R_Group'] != 'ERC'].copy()\n",
    "\n",
    "#iterate through the date until the end of DF \n",
    "temp2016['Date'] = [next(year_2016) for year in range(len(temp2016))]\n",
    "temp2011['Date'] = [next(year_2011) for year in range(len(temp2011))]\n",
    "#print(temp2016)\n",
    "#print(temp2011)\n",
    "\n",
    "load_dur2 = pd.concat([temp2016, temp2011], ignore_index=True)\n",
    "#print(load_dur2)\n",
    "\n",
    "#convert date to a datetime type \n",
    "load_dur2['Date'] = pd.to_datetime(load_dur2['Date'])\n",
    "load_dur2['DOW'] = load_dur2['Date'].dt.weekday\n",
    "\n",
    "#check if it is a weekday or not \n",
    "weekday = pd.read_csv('inputs/weekday.csv')\n",
    "load_dur2 = pd.merge(load_dur2,weekday,on='DOW',how='left')\n",
    "#print(load_dur2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 1: Monthly, single day type, 24 hours (288 segments)\n",
    "#### Methodology: Using groupby function to group first by month, then by 24 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Region  Month  Hour  Hour_Tot  Load_Tot      Load_Avg\n",
      "0  ERC_REST      1     1        31   1042446  33627.290323\n",
      "1  ERC_REST      1     2        31   1051661  33924.548387\n",
      "2  ERC_REST      1     3        31   1079739  34830.290323\n",
      "3  ERC_REST      1     4        31   1144492  36919.096774\n",
      "4  ERC_REST      1     5        31   1239385  39980.161290\n",
      "number of rows in dataset = 18144\n",
      "\n",
      "        Region R_Group R_Subgroup    Season  Month  Day  Hour  Hour_Counter  \\\n",
      "2042  ERC_REST     ERC       REST  shoulder      3   86     3          2043   \n",
      "2233  ERC_REST     ERC       REST  shoulder      4   94     2          2234   \n",
      "1706  ERC_REST     ERC       REST  shoulder      3   72     3          1707   \n",
      "\n",
      "       Load       Date  DOW  Weekday  Hour_Tot  Load_Tot      Load_Avg  \n",
      "2042  26989 2016-03-26    5    False        31    886708  28603.483871  \n",
      "2233  27006 2016-04-03    6    False        30    870591  29019.700000  \n",
      "1706  27025 2016-03-12    5    False        31    886708  28603.483871  \n",
      "number of rows in dataset = 551880\n"
     ]
    }
   ],
   "source": [
    "case1_load = load_dur2.copy()\n",
    "\n",
    "aggregations = {'Load':['count',sum,'mean']}\n",
    "case1 = case1_load.groupby(['Region','Month','Hour'],as_index=False).agg(aggregations)\n",
    "case1.columns = case1.columns.droplevel(0)\n",
    "case1.columns = ['Region','Month','Hour','Hour_Tot','Load_Tot','Load_Avg']\n",
    "print(case1.head())\n",
    "print('number of rows in dataset =',case1.shape[0])\n",
    "#case1.to_csv('outputs/load_segments_2daytype_monthly_24hr.csv')\n",
    "print()\n",
    "\n",
    "case1_load2 = pd.merge(case1_load,case1,on=['Region','Month','Hour'],how='left')\n",
    "case1_load2 = case1_load2.sort_values(['Region','Load'])\n",
    "print(case1_load2.head(3))\n",
    "print('number of rows in dataset =',case1_load2.shape[0])\n",
    "#case1_load2.to_csv('outputs/load_8760_2daytype_monthly_24hr.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 2: Season, single day-type, 24 hours (72 segments)\n",
    "#### Methodology: Use groupby function to group by season and hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Region  Season_Group  Hour  Hour_Tot  Load_Tot      Load_Avg\n",
      "0  ERC_REST             1     1        90   2928629  32540.322222\n",
      "1  ERC_REST             1     2        90   2929331  32548.122222\n",
      "2  ERC_REST             1     3        90   2978696  33096.622222\n",
      "3  ERC_REST             1     4        90   3116896  34632.177778\n",
      "4  ERC_REST             1     5        90   3346197  37179.966667\n",
      "number of rows in dataset = 7560\n",
      "\n",
      "        Region R_Group R_Subgroup    Season  Month  Day  Hour  Hour_Counter  \\\n",
      "2042  ERC_REST     ERC       REST  shoulder      3   86     3          2043   \n",
      "2233  ERC_REST     ERC       REST  shoulder      4   94     2          2234   \n",
      "1706  ERC_REST     ERC       REST  shoulder      3   72     3          1707   \n",
      "\n",
      "       Load       Date  DOW  Weekday  Season_Group  Hour_Tot  Load_Tot  \\\n",
      "2042  26989 2016-03-26    5    False             2       122   3603145   \n",
      "2233  27006 2016-04-03    6    False             2       122   3587428   \n",
      "1706  27025 2016-03-12    5    False             2       122   3603145   \n",
      "\n",
      "          Load_Avg  \n",
      "2042  29533.975410  \n",
      "2233  29405.147541  \n",
      "1706  29533.975410  \n",
      "number of rows in dataset = 551880\n"
     ]
    }
   ],
   "source": [
    "case2_load = load_dur2.copy()\n",
    "case2_seasons = pd.read_csv('inputs/season_bimonthly.csv')\n",
    "case2_seasons = case2_seasons.drop(['bimonthly'], axis=1)\n",
    "case2_seasons = case2_seasons.rename(columns={'seasonal':'Season_Group','month':'Month'})\n",
    "\n",
    "case2_load = pd.merge(case2_load, case2_seasons, on='Month', how='left')\n",
    "#print(case4_load)\n",
    "\n",
    "aggregations = {'Load':['count',sum,'mean']}\n",
    "case2 = case2_load.groupby(['Region','Season_Group','Hour'],as_index=False).agg(aggregations)\n",
    "case2.columns = case2.columns.droplevel(0)\n",
    "case2.columns = ['Region','Season_Group','Hour','Hour_Tot','Load_Tot','Load_Avg']\n",
    "print(case2.head())\n",
    "print('number of rows in dataset =',case2.shape[0])\n",
    "case2.to_csv('outputs/load_segments_2daytype_season_24hr.csv')\n",
    "print()\n",
    "\n",
    "case2_load2 = pd.merge(case2_load,case2,on=['Region','Season_Group','Hour'],how='left')\n",
    "case2_load2 = case2_load2.sort_values(['Region','Load'])\n",
    "print(case2_load2.head(3))\n",
    "print('number of rows in dataset =',case2_load2.shape[0])\n",
    "case2_load2.to_csv('outputs/load_8760_2daytype_season_24hr.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 3: Monthly, weekend/weekday, 24 hours (576 segments)\n",
    "#### Metholodogy: Use groupby function to group by month, then weekend/weekday, then by 24 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Region  Month  Hour  Hour_Tot  Load_Tot      Load_Avg\n",
      "0  ERC_REST      1     1        31   1042446  33627.290323\n",
      "1  ERC_REST      1     2        31   1051661  33924.548387\n",
      "2  ERC_REST      1     3        31   1079739  34830.290323\n",
      "3  ERC_REST      1     4        31   1144492  36919.096774\n",
      "4  ERC_REST      1     5        31   1239385  39980.161290\n",
      "number of rows in dataset = 36288\n",
      "\n",
      "        Region R_Group R_Subgroup    Season  Month  Day  Hour  Hour_Counter  \\\n",
      "2042  ERC_REST     ERC       REST  shoulder      3   86     3          2043   \n",
      "2233  ERC_REST     ERC       REST  shoulder      4   94     2          2234   \n",
      "1706  ERC_REST     ERC       REST  shoulder      3   72     3          1707   \n",
      "1538  ERC_REST     ERC       REST  shoulder      3   65     3          1539   \n",
      "1537  ERC_REST     ERC       REST  shoulder      3   65     2          1538   \n",
      "\n",
      "       Load       Date  DOW  Weekday  Hour_Tot  Load_Tot   Load_Avg  \n",
      "2042  26989 2016-03-26    5    False         8    226231  28278.875  \n",
      "2233  27006 2016-04-03    6    False         8    228827  28603.375  \n",
      "1706  27025 2016-03-12    5    False         8    226231  28278.875  \n",
      "1538  27059 2016-03-05    5    False         8    226231  28278.875  \n",
      "1537  27069 2016-03-05    5    False         8    223600  27950.000  \n",
      "number of rows in dataset = 551880\n"
     ]
    }
   ],
   "source": [
    "case3_load = load_dur2.copy()\n",
    "\n",
    "aggregations = {'Load':['count',sum,'mean']}\n",
    "case3 = case3_load.groupby(['Region','Month','Weekday','Hour'],as_index=False).agg(aggregations)\n",
    "case3.columns = case3.columns.droplevel(0)\n",
    "case3.columns = ['Region','Month','Weekday','Hour','Hour_Tot','Load_Tot','Load_Avg']\n",
    "print(case1.head())\n",
    "print('number of rows in dataset =',case3.shape[0])\n",
    "#case3.to_csv('outputs/load_segments_2daytype_monthly_wkd.csv')\n",
    "print()\n",
    "\n",
    "case3_load2 = pd.merge(case3_load,case3,on=['Region','Month','Weekday','Hour'],how='left')\n",
    "case3_load2 = case3_load2.sort_values(['Region','Load'])\n",
    "print(case3_load2.head())\n",
    "print('number of rows in dataset =',case3_load2.shape[0])\n",
    "#case3_load2.to_csv('outputs/load_8760_2daytype_monthly_wkd.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 4: Season, weekend/weekday, 24 hours (144 segments)\n",
    "#### Methodology: groupby season, weekday, hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Region  Season_Group  Weekday  Hour  Hour_Tot  Load_Tot      Load_Avg\n",
      "0  ERC_REST             1    False     1        26    849384  32668.615385\n",
      "1  ERC_REST             1    False     2        26    849398  32669.153846\n",
      "2  ERC_REST             1    False     3        26    861202  33123.153846\n",
      "3  ERC_REST             1    False     4        26    893024  34347.076923\n",
      "4  ERC_REST             1    False     5        26    945126  36351.000000\n",
      "number of rows in dataset = 15120\n",
      "\n",
      "        Region R_Group R_Subgroup    Season  Month  Day  Hour  Hour_Counter  \\\n",
      "2042  ERC_REST     ERC       REST  shoulder      3   86     3          2043   \n",
      "2233  ERC_REST     ERC       REST  shoulder      4   94     2          2234   \n",
      "1706  ERC_REST     ERC       REST  shoulder      3   72     3          1707   \n",
      "1538  ERC_REST     ERC       REST  shoulder      3   65     3          1539   \n",
      "1537  ERC_REST     ERC       REST  shoulder      3   65     2          1538   \n",
      "\n",
      "       Load       Date  DOW  Weekday  Season_Group  Hour_Tot  Load_Tot  \\\n",
      "2042  26989 2016-03-26    5    False             2        34    986931   \n",
      "2233  27006 2016-04-03    6    False             2        34    983634   \n",
      "1706  27025 2016-03-12    5    False             2        34    986931   \n",
      "1538  27059 2016-03-05    5    False             2        34    986931   \n",
      "1537  27069 2016-03-05    5    False             2        34    983634   \n",
      "\n",
      "          Load_Avg  \n",
      "2042  29027.382353  \n",
      "2233  28930.411765  \n",
      "1706  29027.382353  \n",
      "1538  29027.382353  \n",
      "1537  28930.411765  \n",
      "number of rows in dataset = 551880\n"
     ]
    }
   ],
   "source": [
    "case4_load = load_dur2.copy()\n",
    "case4_seasons = pd.read_csv('inputs/season_bimonthly.csv')\n",
    "case4_seasons = case4_seasons.drop(['bimonthly'], axis=1)\n",
    "case4_seasons = case4_seasons.rename(columns={'seasonal':'Season_Group','month':'Month'})\n",
    "\n",
    "case4_load = pd.merge(case4_load, case4_seasons, on='Month', how='left')\n",
    "#print(case4_load)\n",
    "\n",
    "aggregations = {'Load':['count',sum,'mean']}\n",
    "case4 = case4_load.groupby(['Region','Season_Group','Weekday','Hour'],as_index=False).agg(aggregations)\n",
    "case4.columns = case4.columns.droplevel(0)\n",
    "case4.columns = ['Region','Season_Group','Weekday','Hour','Hour_Tot','Load_Tot','Load_Avg']\n",
    "print(case4.head())\n",
    "print('number of rows in dataset =',case4.shape[0])\n",
    "#case4.to_csv('outputs/load_segments_2daytype_season_wkd.csv')\n",
    "print()\n",
    "\n",
    "case4_load2 = pd.merge(case4_load,case4,on=['Region','Season_Group','Weekday','Hour'],how='left')\n",
    "case4_load2 = case4_load2.sort_values(['Region','Load'])\n",
    "print(case4_load2.head())\n",
    "print('number of rows in dataset =',case4_load2.shape[0])\n",
    "#case4_load2.to_csv('outputs/load_8760_2daytype_season_wkd.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 hour interval day types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Hour_Counter  4-hr\n",
      "0                1     1\n",
      "1                2     1\n",
      "2                3     1\n",
      "3                4     1\n",
      "4                5     2\n",
      "...            ...   ...\n",
      "8755          8756  2189\n",
      "8756          8757  2190\n",
      "8757          8758  2190\n",
      "8758          8759  2190\n",
      "8759          8760  2190\n",
      "\n",
      "[8760 rows x 2 columns]\n",
      "          Region R_Group R_Subgroup  Season  Month  Day  Hour  Hour_Counter  \\\n",
      "0       ERC_REST     ERC       REST  winter      1    1     1             1   \n",
      "1       ERC_REST     ERC       REST  winter      1    1     2             2   \n",
      "2       ERC_REST     ERC       REST  winter      1    1     3             3   \n",
      "3       ERC_REST     ERC       REST  winter      1    1     4             4   \n",
      "4       ERC_REST     ERC       REST  winter      1    1     5             5   \n",
      "...          ...     ...        ...     ...    ...  ...   ...           ...   \n",
      "551875  WEC_SDGE     WEC       SDGE  winter     12  365    20          8756   \n",
      "551876  WEC_SDGE     WEC       SDGE  winter     12  365    21          8757   \n",
      "551877  WEC_SDGE     WEC       SDGE  winter     12  365    22          8758   \n",
      "551878  WEC_SDGE     WEC       SDGE  winter     12  365    23          8759   \n",
      "551879  WEC_SDGE     WEC       SDGE  winter     12  365    24          8760   \n",
      "\n",
      "         Load       Date  DOW  Weekday  4-hr  \n",
      "0       34807 2016-01-01    4     True     1  \n",
      "1       34551 2016-01-01    4     True     1  \n",
      "2       34788 2016-01-01    4     True     1  \n",
      "3       35531 2016-01-01    4     True     1  \n",
      "4       36633 2016-01-01    4     True     2  \n",
      "...       ...        ...  ...      ...   ...  \n",
      "551875   2809 2011-12-31    5    False  2189  \n",
      "551876   2675 2011-12-31    5    False  2190  \n",
      "551877   2524 2011-12-31    5    False  2190  \n",
      "551878   2362 2011-12-31    5    False  2190  \n",
      "551879   2206 2011-12-31    5    False  2190  \n",
      "\n",
      "[551880 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "#read in 4 hour interval counter\n",
    "interval_4hr = pd.read_csv('inputs/sequential_hours.csv')\n",
    "interval_4hr = interval_4hr.drop(columns=['2-hr','8-hr','12-hr','24-hr','48-hr','120-hr'])\n",
    "print(interval_4hr)\n",
    "\n",
    "load_dur3 = pd.merge(load_dur2,interval_4hr,on='Hour_Counter',how='left')\n",
    "print(load_dur3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 5: Monthly, single day type, 4 hour intervals (72 segments)\n",
    "#### Methodology: use groupby by month, 4 hour intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Region  Month  4-hr  Hour_Tot  Load_Tot  Load_Avg\n",
      "0  ERC_REST      1     1         4    139677  34919.25\n",
      "1  ERC_REST      1     2         4    153285  38321.25\n",
      "2  ERC_REST      1     3         4    160446  40111.50\n",
      "3  ERC_REST      1     4         4    155314  38828.50\n",
      "4  ERC_REST      1     5         4    162472  40618.00\n",
      "number of rows in dataset = 137970\n",
      "\n",
      "        Region R_Group R_Subgroup    Season  Month  Day  Hour  Hour_Counter  \\\n",
      "2042  ERC_REST     ERC       REST  shoulder      3   86     3          2043   \n",
      "2233  ERC_REST     ERC       REST  shoulder      4   94     2          2234   \n",
      "1706  ERC_REST     ERC       REST  shoulder      3   72     3          1707   \n",
      "1538  ERC_REST     ERC       REST  shoulder      3   65     3          1539   \n",
      "1537  ERC_REST     ERC       REST  shoulder      3   65     2          1538   \n",
      "\n",
      "       Load       Date  DOW  Weekday  4-hr  Hour_Tot  Load_Tot  Load_Avg  \n",
      "2042  26989 2016-03-26    5    False   511         4    108862  27215.50  \n",
      "2233  27006 2016-04-03    6    False   559         4    111068  27767.00  \n",
      "1706  27025 2016-03-12    5    False   427         4    109231  27307.75  \n",
      "1538  27059 2016-03-05    5    False   385         4    108948  27237.00  \n",
      "1537  27069 2016-03-05    5    False   385         4    108948  27237.00  \n",
      "number of rows in dataset = 551880\n"
     ]
    }
   ],
   "source": [
    "case5_load = load_dur3.copy()\n",
    "\n",
    "aggregations = {'Load':['count',sum,'mean']}\n",
    "case5 = case5_load.groupby(['Region','Month','4-hr'],as_index=False).agg(aggregations)\n",
    "case5.columns = case5.columns.droplevel(0)\n",
    "case5.columns = ['Region','Month','4-hr','Hour_Tot','Load_Tot','Load_Avg']\n",
    "print(case5.head())\n",
    "print('number of rows in dataset =',case5.shape[0])\n",
    "#case5.to_csv('outputs/load_segments_2daytype_month_4hr.csv')\n",
    "print()\n",
    "\n",
    "case5_load2 = pd.merge(case5_load,case5,on=['Region','Month','4-hr'],how='left')\n",
    "case5_load2 = case5_load2.sort_values(['Region','Load'])\n",
    "print(case5_load2.head())\n",
    "print('number of rows in dataset =',case5_load2.shape[0])\n",
    "#case5_load2.to_csv('outputs/load_8760_2daytype_month_4hr.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 6: Bi-monthly weekend/weekday day-types, 4-hour intervals\n",
    "#### Methodology: use groupby function and bimonthly groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Region  Bimonth  4-hr  Hour_Tot  Load_Tot  Load_Avg\n",
      "0  ERC_REST        1     1         4    139677  34919.25\n",
      "1  ERC_REST        1     2         4    153285  38321.25\n",
      "2  ERC_REST        1     3         4    160446  40111.50\n",
      "3  ERC_REST        1     4         4    155314  38828.50\n",
      "4  ERC_REST        1     5         4    162472  40618.00\n",
      "number of rows in dataset = 137970\n",
      "\n",
      "        Region R_Group R_Subgroup    Season  Month  Day  Hour  Hour_Counter  \\\n",
      "2042  ERC_REST     ERC       REST  shoulder      3   86     3          2043   \n",
      "2233  ERC_REST     ERC       REST  shoulder      4   94     2          2234   \n",
      "1706  ERC_REST     ERC       REST  shoulder      3   72     3          1707   \n",
      "1538  ERC_REST     ERC       REST  shoulder      3   65     3          1539   \n",
      "1537  ERC_REST     ERC       REST  shoulder      3   65     2          1538   \n",
      "\n",
      "       Load       Date  DOW  Weekday  4-hr  Bimonth  Hour_Tot  Load_Tot  \\\n",
      "2042  26989 2016-03-26    5    False   511        2         4    108862   \n",
      "2233  27006 2016-04-03    6    False   559        2         4    111068   \n",
      "1706  27025 2016-03-12    5    False   427        2         4    109231   \n",
      "1538  27059 2016-03-05    5    False   385        2         4    108948   \n",
      "1537  27069 2016-03-05    5    False   385        2         4    108948   \n",
      "\n",
      "      Load_Avg  \n",
      "2042  27215.50  \n",
      "2233  27767.00  \n",
      "1706  27307.75  \n",
      "1538  27237.00  \n",
      "1537  27237.00  \n",
      "number of rows in dataset = 551880\n"
     ]
    }
   ],
   "source": [
    "case6_load = load_dur3.copy()\n",
    "case6_bimonth = pd.read_csv('inputs/season_bimonthly.csv')\n",
    "case6_bimonth = case6_bimonth.drop(['seasonal'], axis=1)\n",
    "case6_bimonth = case6_bimonth.rename(columns={'bimonthly':'Bimonth','month':'Month'})\n",
    "\n",
    "case6_load = pd.merge(case6_load, case6_bimonth, on='Month', how='left')\n",
    "#print(case4_load)\n",
    "\n",
    "aggregations = {'Load':['count',sum,'mean']}\n",
    "case6 = case6_load.groupby(['Region','Bimonth','4-hr'],as_index=False).agg(aggregations)\n",
    "case6.columns = case6.columns.droplevel(0)\n",
    "case6.columns = ['Region','Bimonth','4-hr','Hour_Tot','Load_Tot','Load_Avg']\n",
    "print(case6.head())\n",
    "print('number of rows in dataset =',case6.shape[0])\n",
    "#case6.to_csv('outputs/load_segments_2daytype_bimonth_4hr.csv')\n",
    "print()\n",
    "\n",
    "case6_load2 = pd.merge(case6_load,case6,on=['Region','Bimonth','4-hr'],how='left')\n",
    "case6_load2 = case6_load2.sort_values(['Region','Load'])\n",
    "print(case6_load2.head())\n",
    "print('number of rows in dataset =',case6_load2.shape[0])\n",
    "#case6_load2.to_csv('outputs/load_8760_2daytype_bimonth_4hr.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 7: Season-based months, weekend/weekday day-types, 4-hour intervals\n",
    "#### Methodology: groupby function and applied season groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Region    Season  Weekday  4-hr  Hour_Tot  Load_Tot  Load_Avg\n",
      "0  ERC_REST  shoulder    False   385         4    108948  27237.00\n",
      "1  ERC_REST  shoulder    False   386         4    118864  29716.00\n",
      "2  ERC_REST  shoulder    False   387         4    131620  32905.00\n",
      "3  ERC_REST  shoulder    False   388         4    135694  33923.50\n",
      "4  ERC_REST  shoulder    False   389         4    142563  35640.75\n",
      "number of rows in dataset = 137970\n",
      "\n",
      "        Region R_Group R_Subgroup    Season  Month  Day  Hour  Hour_Counter  \\\n",
      "2042  ERC_REST     ERC       REST  shoulder      3   86     3          2043   \n",
      "2233  ERC_REST     ERC       REST  shoulder      4   94     2          2234   \n",
      "1706  ERC_REST     ERC       REST  shoulder      3   72     3          1707   \n",
      "1538  ERC_REST     ERC       REST  shoulder      3   65     3          1539   \n",
      "1537  ERC_REST     ERC       REST  shoulder      3   65     2          1538   \n",
      "\n",
      "       Load       Date  DOW  Weekday  4-hr  Season_Group  Hour_Tot  Load_Tot  \\\n",
      "2042  26989 2016-03-26    5    False   511             2         4    108862   \n",
      "2233  27006 2016-04-03    6    False   559             2         4    111068   \n",
      "1706  27025 2016-03-12    5    False   427             2         4    109231   \n",
      "1538  27059 2016-03-05    5    False   385             2         4    108948   \n",
      "1537  27069 2016-03-05    5    False   385             2         4    108948   \n",
      "\n",
      "      Load_Avg  \n",
      "2042  27215.50  \n",
      "2233  27767.00  \n",
      "1706  27307.75  \n",
      "1538  27237.00  \n",
      "1537  27237.00  \n",
      "number of rows in dataset = 551880\n"
     ]
    }
   ],
   "source": [
    "case7_load = load_dur3.copy()\n",
    "case7_seasons = pd.read_csv('inputs/season_bimonthly.csv')\n",
    "case7_seasons = case7_seasons.drop(['bimonthly'], axis=1)\n",
    "case7_seasons = case7_seasons.rename(columns={'seasonal':'Season_Group','month':'Month'})\n",
    "\n",
    "case7_load = pd.merge(case7_load, case7_seasons, on='Month', how='left')\n",
    "#print(case4_load)\n",
    "\n",
    "aggregations = {'Load':['count',sum,'mean']}\n",
    "case7 = case7_load.groupby(['Region','Season','Weekday','4-hr'],as_index=False).agg(aggregations)\n",
    "case7.columns = case7.columns.droplevel(0)\n",
    "case7.columns = ['Region','Season','Weekday','4-hr','Hour_Tot','Load_Tot','Load_Avg']\n",
    "print(case7.head())\n",
    "print('number of rows in dataset =',case7.shape[0])\n",
    "case7.to_csv('outputs/load_segments_2daytype_season_wkd_4hr.csv')\n",
    "print()\n",
    "\n",
    "case7_load2 = pd.merge(case7_load,case7,on=['Region','Season','Weekday','4-hr'],how='left')\n",
    "case7_load2 = case7_load2.sort_values(['Region','Load'])\n",
    "print(case7_load2.head())\n",
    "print('number of rows in dataset =',case7_load2.shape[0])\n",
    "case7_load2.to_csv('outputs/load_8760_2daytype_season_wkd_4hr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
