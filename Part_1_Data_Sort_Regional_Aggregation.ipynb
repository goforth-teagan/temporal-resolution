{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case: Grouping hours by interconnect\n",
    "### Details: Group hours first by interconnect load in the same 6 load groups as used before, then split into regions and split by 3 seasons and 4 times of day\\\n",
    "#### Methodology: Use similar code as the one used to organize groups by season, but for interconnects, and then split into and sort by region, season, and time of day. \n",
    "### 1: Group by interconnect and 6 load groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Region R_Group R_Subgroup    Season  Month  Day  Hour  Hour_Counter  \\\n",
      "0       ERC_REST     ERC       REST    summer      8  223    15          5343   \n",
      "1       ERC_REST     ERC       REST    summer      8  223    14          5342   \n",
      "2       ERC_REST     ERC       REST    summer      8  223    16          5344   \n",
      "3       ERC_REST     ERC       REST    summer      8  222    15          5319   \n",
      "4       ERC_REST     ERC       REST    summer      8  224    14          5366   \n",
      "...          ...     ...        ...       ...    ...  ...   ...           ...   \n",
      "551875  WECC_IID     WEC        IID  shoulder      3   86     4          2044   \n",
      "551876  WECC_IID     WEC        IID  shoulder      4  101     4          2404   \n",
      "551877  WECC_IID     WEC        IID  shoulder     11  310     3          7419   \n",
      "551878  WECC_IID     WEC        IID  shoulder      4  100     4          2380   \n",
      "551879  WECC_IID     WEC        IID  shoulder      4   99     3          2355   \n",
      "\n",
      "         Load      TOD Interconnect  Group  \n",
      "0       67599  middday          ERC      1  \n",
      "1       67511  middday          ERC      1  \n",
      "2       67313  middday          ERC      1  \n",
      "3       67174  middday          ERC      1  \n",
      "4       67152  middday          ERC      1  \n",
      "...       ...      ...          ...    ...  \n",
      "551875    323    night          WEC      6  \n",
      "551876    323    night          WEC      6  \n",
      "551877    322    night          WEC      6  \n",
      "551878    321    night          WEC      6  \n",
      "551879    320    night          WEC      6  \n",
      "\n",
      "[551880 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "#importing packages needed for analysis\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from pandas import DataFrame\n",
    "\n",
    "path = os.getcwd()\n",
    "#print(path)\n",
    "\n",
    "load_dur = pd.read_csv('outputs/load_long_format.csv')\n",
    "\n",
    "#first, split by interconnect and 6 load groups\n",
    "inter_load = load_dur.copy()\n",
    "tod = pd.read_csv('inputs/time_of_day.csv')\n",
    "\n",
    "inter_load = pd.merge(inter_load,tod,on='Hour',how='left')\n",
    "\n",
    "#identifying different interconnects\n",
    "inter_load['Interconnect'] = 'Other'\n",
    "inter_load.loc[inter_load['R_Group'] == 'WEC', 'Interconnect'] = 'WEC'\n",
    "inter_load.loc[inter_load['R_Group'] == 'ERC', 'Interconnect'] = 'ERC'\n",
    "      \n",
    "#Create a list of interconnects of all regions (551880 rows)\n",
    "interconnects = inter_load.copy()\n",
    "interconnects = interconnects[['Interconnect','Hour_Counter']]\n",
    "#print(interconnects.head())\n",
    "#print(interconnects.shape)\n",
    "\n",
    "#get the number of hours in each interconnect\n",
    "inter_count = interconnects.groupby('Interconnect',as_index=False).count().rename(columns={'Hour_Counter':'Interconnect_Tot'})\n",
    "inter_count = inter_count.sort_values('Interconnect')\n",
    "#print(inter_count)\n",
    "\n",
    "#read in the group shares data\n",
    "group2 = pd.read_csv('inputs/group_shares.csv')\n",
    "\n",
    "#combined the group shares data with the interconnect/hours data\n",
    "#NOTE: if there are ever more than three interconnects or regions, this code should be updated\n",
    "group2[inter_count.iloc[0,0]] = group2['Share']*inter_count.iloc[0,1]\n",
    "group2[inter_count.iloc[1,0]] = group2['Share']*inter_count.iloc[1,1]\n",
    "group2[inter_count.iloc[2,0]] = group2['Share']*inter_count.iloc[2,1]\n",
    "group_inter2 = pd.melt(group2,id_vars=['Group','Share'],var_name='Interconnect',value_name='Interconnect_Ct')\n",
    "group_inter2['Interconnect_Counter'] = group_inter2['Interconnect_Ct'].cumsum()\n",
    "group_inter2['Interconnect_Counter'] = round(group_inter2['Interconnect_Counter'])\n",
    "#print(group2.dtypes)\n",
    "#print(group2)\n",
    "#print(group_inter)\n",
    "#print()\n",
    "\n",
    "#sort by interconnect, and then load in ascending order\n",
    "inter_load_2 = inter_load.sort_values(by=['Interconnect','Load'], ascending=[True, False]).reset_index(drop=True)\n",
    "inter_load_2['Interconnect_Counter'] = inter_load_2.index + 1.0 \n",
    "#print(inter_load_sort)\n",
    "\n",
    "#use interconnect_counter to apply groups to each interconnect \n",
    "#create list of group_inter with just the group and interconnect listed\n",
    "group_inter_index = group_inter2[['Group','Interconnect_Counter']].copy()\n",
    "\n",
    "#merge to apply groups to each interconnect value based on the counter  \n",
    "inter_load_2 = pd.merge_asof(inter_load_2, group_inter_index, on='Interconnect_Counter', direction='forward')\n",
    "inter_load_2 = inter_load_2.drop(columns=['Interconnect_Counter']).reset_index(drop=True)\n",
    "inter_load_2 = inter_load_2.drop(inter_load_2.columns[0], axis=1)\n",
    "print(inter_load_2)\n",
    "#inter_load_2.to_csv('outputs/load_duration_8760_interconnect.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: Sort by region, season, and time of day\n",
    "### 3: Average load based on groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort by region, season, and time of day \n",
    "inter_load_3 = inter_load_2.sort_values(['Interconnect','Group','Region','Season','TOD'])\n",
    "\n",
    "#average load based on order of groups\n",
    "aggregations = {'Load':['count',sum,'mean']}\n",
    "case = inter_load_3.groupby(['Interconnect','Group','Region','Season','TOD'],as_index=False).agg(aggregations)\n",
    "case.columns = case.columns.droplevel(0)\n",
    "case.columns = ['Interconnect','Group','Region','Season','TOD','Hour_Tot','Load_Tot','Load_Avg']\n",
    "#print(case.head())\n",
    "#print('number of rows in dataset =',case.shape[0])\n",
    "#case.to_csv('outputs/load_segments_interconnect.csv')\n",
    "#print()\n",
    "\n",
    "inter_load_4 = pd.merge(inter_load_3,case,on=['Interconnect','Group','Region','Season','TOD'],how='left')\n",
    "inter_load_4 = inter_load_4.sort_values(['Region','Load']).reset_index(drop=True)\n",
    "inter_load_4 = inter_load_4.drop(inter_load_4.columns[0], axis=1)\n",
    "#print(inter_load_4.head(3))\n",
    "#print('number of rows in dataset =',inter_load_4.shape[0])\n",
    "#inter_load_4.to_csv('outputs/load_8760_interconnect.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case: NERC Region Grouping\n",
    "### Details: First group the regions by their market group and separate into load groups there. Then, split into regions and group by season and time of day. \n",
    "#### Methodology: Similar, if not identical to the interconnect approach. They will be grouped by market groups instead of interconnects, but everything else remains the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Region R_Group R_Subgroup NERC_Region  Season  Month  Day    TOD  \\\n",
      "0       ERC_REST     ERC       REST       ERCOT  winter      1    1  night   \n",
      "1       ERC_REST     ERC       REST       ERCOT  winter      1    1  night   \n",
      "2       ERC_REST     ERC       REST       ERCOT  winter      1    1  night   \n",
      "3       ERC_REST     ERC       REST       ERCOT  winter      1    1  night   \n",
      "4       ERC_REST     ERC       REST       ERCOT  winter      1    1  night   \n",
      "...          ...     ...        ...         ...     ...    ...  ...    ...   \n",
      "551875  WEC_SDGE     WEC       SDGE        CAMX  winter     12  365  night   \n",
      "551876  WEC_SDGE     WEC       SDGE        CAMX  winter     12  365  night   \n",
      "551877  WEC_SDGE     WEC       SDGE        CAMX  winter     12  365  night   \n",
      "551878  WEC_SDGE     WEC       SDGE        CAMX  winter     12  365  night   \n",
      "551879  WEC_SDGE     WEC       SDGE        CAMX  winter     12  365  night   \n",
      "\n",
      "        Hour  Hour_Counter   Load  \n",
      "0          1             1  34807  \n",
      "1          2             2  34551  \n",
      "2          3             3  34788  \n",
      "3          4             4  35531  \n",
      "4          5             5  36633  \n",
      "...      ...           ...    ...  \n",
      "551875    20          8756   2809  \n",
      "551876    21          8757   2675  \n",
      "551877    22          8758   2524  \n",
      "551878    23          8759   2362  \n",
      "551879    24          8760   2206  \n",
      "\n",
      "[551880 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "#match NERC region ID to the region\n",
    "nerc_id = pd.read_csv('inputs/nerc_regions.csv')\n",
    "\n",
    "#merge NERC regions and load data together\n",
    "nerc_load = pd.merge(load_dur,nerc_id, on='Region', how='left')\n",
    "nerc_load = nerc_load.drop(nerc_load.columns[0], axis=1)\n",
    "\n",
    "#merge TOD info into DF\n",
    "tod = pd.read_csv('inputs/time_of_day.csv')\n",
    "nerc_load = pd.merge(nerc_load,tod,on='Hour',how='left')\n",
    "nerc_load = nerc_load[['Region','R_Group','R_Subgroup','NERC_Region','Season','Month','Day','TOD','Hour','Hour_Counter',\n",
    "                     'Load']]\n",
    "print(nerc_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Region R_Group R_Subgroup NERC_Region    Season  Month  Day  \\\n",
      "0       WECC_SCE     WEC        SCE        CAMX    summer      9  250   \n",
      "1       WECC_SCE     WEC        SCE        CAMX    summer      9  250   \n",
      "2       WECC_SCE     WEC        SCE        CAMX    summer      9  250   \n",
      "3       WECC_SCE     WEC        SCE        CAMX    summer      9  250   \n",
      "4       WECC_SCE     WEC        SCE        CAMX    summer      9  250   \n",
      "...          ...     ...        ...         ...       ...    ...  ...   \n",
      "551875  WECC_IID     WEC        IID        SRSG  shoulder      3   86   \n",
      "551876  WECC_IID     WEC        IID        SRSG  shoulder      4  101   \n",
      "551877  WECC_IID     WEC        IID        SRSG  shoulder     11  310   \n",
      "551878  WECC_IID     WEC        IID        SRSG  shoulder      4  100   \n",
      "551879  WECC_IID     WEC        IID        SRSG  shoulder      4   99   \n",
      "\n",
      "            TOD  Hour  Hour_Counter   Load  Group  \n",
      "0       middday    16          5992  24240      1  \n",
      "1       evening    17          5993  24072      1  \n",
      "2       middday    15          5991  23781      1  \n",
      "3       evening    18          5994  23251      1  \n",
      "4       middday    14          5990  23082      1  \n",
      "...         ...   ...           ...    ...    ...  \n",
      "551875    night     4          2044    323      6  \n",
      "551876    night     4          2404    323      6  \n",
      "551877    night     3          7419    322      6  \n",
      "551878    night     4          2380    321      6  \n",
      "551879    night     3          2355    320      6  \n",
      "\n",
      "[551880 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "#Create a list of interconnects of all regions (551880 rows)\n",
    "nerc_regions = nerc_load.copy()\n",
    "nerc_regions = nerc_regions[['NERC_Region','Hour_Counter']]\n",
    "#print(nerc_regions.head())\n",
    "#print(nerc_regions.shape)\n",
    "\n",
    "#get the number of hours in each interconnect\n",
    "nerc_count = nerc_regions.groupby('NERC_Region',as_index=False).count().rename(columns={'Hour_Counter':'NERC_Tot'})\n",
    "nerc_count = nerc_count.sort_values('NERC_Region')\n",
    "#print(nerc_count)\n",
    "\n",
    "#read in the group shares data\n",
    "group4 = pd.read_csv('inputs/group_shares.csv')\n",
    "\n",
    "#combined the group shares data with the interconnect/hours data\n",
    "#NOTE: there are 15 NERC regions\n",
    "group4[nerc_count.iloc[0,0]] = group4['Share']*nerc_count.iloc[0,1]\n",
    "group4[nerc_count.iloc[1,0]] = group4['Share']*nerc_count.iloc[1,1]\n",
    "group4[nerc_count.iloc[2,0]] = group4['Share']*nerc_count.iloc[2,1]\n",
    "group4[nerc_count.iloc[3,0]] = group4['Share']*nerc_count.iloc[3,1]\n",
    "group4[nerc_count.iloc[4,0]] = group4['Share']*nerc_count.iloc[4,1]\n",
    "group4[nerc_count.iloc[5,0]] = group4['Share']*nerc_count.iloc[5,1]\n",
    "group4[nerc_count.iloc[6,0]] = group4['Share']*nerc_count.iloc[6,1]\n",
    "group4[nerc_count.iloc[7,0]] = group4['Share']*nerc_count.iloc[7,1]\n",
    "group4[nerc_count.iloc[8,0]] = group4['Share']*nerc_count.iloc[8,1]\n",
    "group4[nerc_count.iloc[9,0]] = group4['Share']*nerc_count.iloc[9,1]\n",
    "group4[nerc_count.iloc[10,0]] = group4['Share']*nerc_count.iloc[10,1]\n",
    "group4[nerc_count.iloc[11,0]] = group4['Share']*nerc_count.iloc[11,1]\n",
    "group4[nerc_count.iloc[12,0]] = group4['Share']*nerc_count.iloc[12,1]\n",
    "group4[nerc_count.iloc[13,0]] = group4['Share']*nerc_count.iloc[13,1]\n",
    "group4[nerc_count.iloc[14,0]] = group4['Share']*nerc_count.iloc[14,1]\n",
    "group_nerc = pd.melt(group4,id_vars=['Group','Share'],var_name='NERC_Region',value_name='NERC_Ct')\n",
    "group_nerc['NERC_Counter'] = group_nerc['NERC_Ct'].cumsum()\n",
    "group_nerc['NERC_Counter'] = round(group_nerc['NERC_Counter'])\n",
    "#print(group4.dtypes)\n",
    "#print(group4)\n",
    "#print(group_nerc)\n",
    "#print()\n",
    "\n",
    "#sort by interconnect, and then load in ascending order\n",
    "nerc_load_2 = nerc_load.sort_values(by=['NERC_Region','Load'], ascending=[True, False]).reset_index(drop=True)\n",
    "nerc_load_2['NERC_Counter'] = nerc_load_2.index + 1.0 \n",
    "#print(nerc_load_2)\n",
    "\n",
    "#use nerc_counter to apply groups to each nerc region \n",
    "#create list of group_inter with just the group and nerc region listed\n",
    "group_nerc_index = group_nerc[['Group','NERC_Counter']].copy()\n",
    "\n",
    "#merge to apply groups to each NERC region value based on the counter  \n",
    "nerc_load_2 = pd.merge_asof(nerc_load_2, group_nerc_index, on='NERC_Counter', direction='forward')\n",
    "nerc_load_2 = nerc_load_2.drop(columns=['NERC_Counter'])\n",
    "print(nerc_load_2)\n",
    "#nerc_load_2.to_csv('outputs/load_duration_8760_NERC_regions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Region R_Group R_Subgroup NERC_Region    Season  Month  Day  \\\n",
      "0       ERC_REST     ERC       REST       ERCOT  shoulder      3   86   \n",
      "1       ERC_REST     ERC       REST       ERCOT  shoulder      4   94   \n",
      "2       ERC_REST     ERC       REST       ERCOT  shoulder      3   72   \n",
      "3       ERC_REST     ERC       REST       ERCOT  shoulder      3   65   \n",
      "4       ERC_REST     ERC       REST       ERCOT  shoulder      3   65   \n",
      "...          ...     ...        ...         ...       ...    ...  ...   \n",
      "551875  WEC_SDGE     WEC       SDGE        CAMX    summer      9  249   \n",
      "551876  WEC_SDGE     WEC       SDGE        CAMX    summer      9  250   \n",
      "551877  WEC_SDGE     WEC       SDGE        CAMX    summer      9  250   \n",
      "551878  WEC_SDGE     WEC       SDGE        CAMX    summer      9  250   \n",
      "551879  WEC_SDGE     WEC       SDGE        CAMX    summer      9  250   \n",
      "\n",
      "            TOD  Hour  Hour_Counter   Load  Group  Hour_Tot  Load_Tot  \\\n",
      "0         night     3          2043  26989      5       536  15548425   \n",
      "1         night     2          2234  27006      5       536  15548425   \n",
      "2         night     3          1707  27025      5       536  15548425   \n",
      "3         night     3          1539  27059      5       536  15548425   \n",
      "4         night     2          1538  27069      5       536  15548425   \n",
      "...         ...   ...           ...    ...    ...       ...       ...   \n",
      "551875  evening    17          5969   4434      5       301    931761   \n",
      "551876  middday    14          5990   4446      5       682   2085017   \n",
      "551877  evening    17          5993   4465      5       301    931761   \n",
      "551878  middday    15          5991   4470      5       682   2085017   \n",
      "551879  middday    16          5992   4479      5       682   2085017   \n",
      "\n",
      "            Load_Avg  \n",
      "0       29008.255597  \n",
      "1       29008.255597  \n",
      "2       29008.255597  \n",
      "3       29008.255597  \n",
      "4       29008.255597  \n",
      "...              ...  \n",
      "551875   3095.551495  \n",
      "551876   3057.209677  \n",
      "551877   3095.551495  \n",
      "551878   3057.209677  \n",
      "551879   3057.209677  \n",
      "\n",
      "[551880 rows x 15 columns]\n",
      "number of rows in dataset = 551880\n"
     ]
    }
   ],
   "source": [
    "#sort by region, season, and time of day \n",
    "nerc_load_3 = nerc_load_2.sort_values(['NERC_Region','Group','Region','Season','TOD'])\n",
    "\n",
    "#average load based on order of groups\n",
    "aggregations2 = {'Load':['count',sum,'mean']}\n",
    "case2 = nerc_load_3.groupby(['NERC_Region','Group','Region','Season','TOD'],as_index=False).agg(aggregations2)\n",
    "case2.columns = case2.columns.droplevel(0)\n",
    "case2.columns = ['NERC_Region','Group','Region','Season','TOD','Hour_Tot','Load_Tot','Load_Avg']\n",
    "#print(case2.head())\n",
    "#print('number of rows in dataset =',case2.shape[0])\n",
    "#case2.to_csv('outputs/load_segments_NERC_region.csv')\n",
    "#print()\n",
    "\n",
    "nerc_load_4 = pd.merge(nerc_load_3,case2,on=['NERC_Region','Group','Region','Season','TOD'],how='left')\n",
    "nerc_load_4 = nerc_load_4.sort_values(['Region','Load']).reset_index(drop=True)\n",
    "print(nerc_load_4)\n",
    "print('number of rows in dataset =',nerc_load_4.shape[0])\n",
    "#nerc_load_4.to_csv('outputs/load_8760_NERC_region.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
