{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Region  Month  Day    Hour 1    Hour 2    Hour 3    Hour 4    Hour 5  \\\n",
      "0  ERC_REST      1    1   34,807    34,551    34,788    35,531    36,633    \n",
      "1  ERC_REST      1    2   34,716    34,719    35,076    35,891    37,091    \n",
      "\n",
      "     Hour 6    Hour 7  ...   Hour 15   Hour 16   Hour 17   Hour 18   Hour 19  \\\n",
      "0   37,780    38,831   ...   38,507    40,084    41,198    40,959    40,549    \n",
      "1   38,207    38,720   ...   33,211    34,968    37,573    38,213    38,257    \n",
      "\n",
      "    Hour 20   Hour 21   Hour 22   Hour 23   Hour 24  \n",
      "0   39,766    38,510    37,012    35,811    35,061   \n",
      "1   37,911    36,743    35,379    34,598    34,444   \n",
      "\n",
      "[2 rows x 27 columns]\n",
      "\n",
      "number of rows in dataset = 27010\n"
     ]
    }
   ],
   "source": [
    "#importing packages needed for analysis\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from pandas import DataFrame\n",
    "\n",
    "path = os.getcwd()\n",
    "#print(path)\n",
    "\n",
    "load_raw = pd.read_csv('inputs/load_duration_curves_raw_data.csv')\n",
    "print(load_raw.head(2))\n",
    "print()\n",
    "print('number of rows in dataset =', load_raw.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows in dataset (including CN) = 27010\n",
      "number of regions in dataset (including CN) = 74\n",
      "number of regional groups in dataset (including CN) = 10\n",
      "\n",
      "  R_Group R_Subgroup    Region  Month  Day    Hour 1    Hour 2    Hour 3  \\\n",
      "0     ERC       REST  ERC_REST      1    1   34,807    34,551    34,788    \n",
      "1     ERC       REST  ERC_REST      1    2   34,716    34,719    35,076    \n",
      "\n",
      "     Hour 4    Hour 5  ...   Hour 15   Hour 16   Hour 17   Hour 18   Hour 19  \\\n",
      "0   35,531    36,633   ...   38,507    40,084    41,198    40,959    40,549    \n",
      "1   35,891    37,091   ...   33,211    34,968    37,573    38,213    38,257    \n",
      "\n",
      "    Hour 20   Hour 21   Hour 22   Hour 23   Hour 24  \n",
      "0   39,766    38,510    37,012    35,811    35,061   \n",
      "1   37,911    36,743    35,379    34,598    34,444   \n",
      "\n",
      "[2 rows x 29 columns]\n",
      "\n",
      "number of rows in dataset after removing CN = 22995\n",
      "number of regions in dataset (excluding CN) = 63\n",
      "number of regional groups in dataset (excluding CN) = 9\n"
     ]
    }
   ],
   "source": [
    "#Organizing regional data\n",
    "\n",
    "#create temporary copy to make changes on\n",
    "load_org = load_raw.copy()\n",
    "print('number of rows in dataset (including CN) =',load_org.shape[0])\n",
    "\n",
    "#Regional IDs\n",
    "unique_r = pd.Series(load_org['Region'].unique()).dropna()\n",
    "rl = unique_r.str.split(\"_\",n=1,expand=True)\n",
    "rl[2] = unique_r\n",
    "#print(rl)\n",
    "print('number of regions in dataset (including CN) =',unique_r.shape[0])\n",
    "\n",
    "#Cleaning up the empty subgroups\n",
    "#print(rl[rl.isna().any(axis=1)])\n",
    "rl.loc[rl[0] == 'NENGREST', 1] = 'REST'\n",
    "rl.loc[rl[0] == 'FRCC', 1] = 'FRCC'\n",
    "\n",
    "#Cleaning up the misnamed groups\n",
    "#unique_g = pd.Series(rl[0].unique()).dropna()\n",
    "#print(unique_g)\n",
    "rl[0] = rl[0].replace('NENGREST','NENG')\n",
    "rl[0] = rl[0].replace('WECC','WEC')\n",
    "unique_g = pd.Series(rl[0].unique()).dropna()\n",
    "print('number of regional groups in dataset (including CN) =',unique_g.shape[0])\n",
    "rl.rename(columns={0 : \"R_Group\", 1: 'R_Subgroup', 2:'Region'},inplace=True)\n",
    "#print(rl.head())\n",
    "\n",
    "#Merging Regional Data to DF\n",
    "load_org = pd.merge(rl,load_org,on='Region',how='right')\n",
    "print()\n",
    "print(load_org.head(2))\n",
    "\n",
    "#Removing Canada\n",
    "load_org = load_org[load_org['R_Group']!=\"CN\"]\n",
    "print()\n",
    "print('number of rows in dataset after removing CN =',load_org.shape[0])\n",
    "unique_r = pd.Series(load_org['Region'].unique()).dropna()\n",
    "print('number of regions in dataset (excluding CN) =',unique_r.shape[0])\n",
    "unique_g = pd.Series(load_org['R_Group'].unique()).dropna()\n",
    "print('number of regional groups in dataset (excluding CN) =',unique_g.shape[0])\n",
    "\n",
    "#for testing only, otherwise comment out the lines below\n",
    "#NOTE: use FRCC for one region, ERC for two regions\n",
    "#load_org = load_org[load_org['R_Group']==\"FRCC\"]\n",
    "#print('number of rows in dataset for testing =',load_org.shape[0])\n",
    "#Organize temporal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Region R_Group R_Subgroup  Season  Month  Day  Hour  Load\n",
      "551878  WECC_WY     WEC         WY  winter     12  364    24  1791\n",
      "551879  WECC_WY     WEC         WY  winter     12  365    24  1834\n",
      "number of rows in dataset = 551880\n"
     ]
    }
   ],
   "source": [
    "#rename hour titles to just the value ('Hour 1' --> 1)\n",
    "load_org.columns = load_org.columns.str.replace('Hour ', '')\n",
    "#print(load_org.head(2))\n",
    "\n",
    "#melt function converts values in wide format to long format\n",
    "load_dur = pd.melt(load_org,id_vars=['R_Group','R_Subgroup','Region','Month','Day'],var_name='Hour',value_name='Load')\n",
    "\n",
    "#print(load_dur.dtypes)\n",
    "\n",
    "#days are counted 1 to 365, not 1 to 31\n",
    "unique_d = pd.Series(load_dur['Day'].unique()).dropna()\n",
    "#print(unique_d.tail(2))\n",
    "\n",
    "#turn hour values to numeric \n",
    "load_dur['Hour'] = pd.to_numeric(load_dur['Hour'],errors='coerce')\n",
    "unique_h = pd.Series(load_dur['Hour'].unique()).dropna()\n",
    "#print(unique_h.tail(2))\n",
    "\n",
    "#turn load values to numeric \n",
    "load_dur['Load'] = pd.to_numeric(load_dur['Load'].str.replace(\",\",\"\"),errors='coerce')\n",
    "#print(load_dur.head(2))\n",
    "\n",
    "season_month = pd.read_csv('inputs/season_months.csv')\n",
    "load_dur = pd.merge(load_dur,season_month, on='Month', how='left')\n",
    "\n",
    "#organized long format data to new csv file\n",
    "load_dur = load_dur[['Region','R_Group','R_Subgroup','Season','Month','Day','Hour','Load']]\n",
    "load_dur.to_csv('outputs/load_long_format.csv')\n",
    "print(load_dur.tail(2))\n",
    "print('number of rows in dataset =',load_dur.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solar Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
