{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output files are written out in parent directory: C:\\Users\\tgoforth\\Documents\\IPM temporal resolution project\\outputs\n",
      "\n",
      "     Region  Month  Day    Hour 1    Hour 2    Hour 3    Hour 4    Hour 5  \\\n",
      "0  ERC_REST      1    1   34,807    34,551    34,788    35,531    36,633    \n",
      "1  ERC_REST      1    2   34,716    34,719    35,076    35,891    37,091    \n",
      "\n",
      "     Hour 6    Hour 7  ...   Hour 15   Hour 16   Hour 17   Hour 18   Hour 19  \\\n",
      "0   37,780    38,831   ...   38,507    40,084    41,198    40,959    40,549    \n",
      "1   38,207    38,720   ...   33,211    34,968    37,573    38,213    38,257    \n",
      "\n",
      "    Hour 20   Hour 21   Hour 22   Hour 23   Hour 24  \n",
      "0   39,766    38,510    37,012    35,811    35,061   \n",
      "1   37,911    36,743    35,379    34,598    34,444   \n",
      "\n",
      "[2 rows x 27 columns]\n",
      "\n",
      "number of rows in dataset = 27010\n"
     ]
    }
   ],
   "source": [
    "#importing packages needed for analysis\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from pandas import DataFrame\n",
    "from itertools import cycle\n",
    "pd.set_option('display.max_rows',500)\n",
    "\n",
    "path = os.getcwd()\n",
    "#print(path)\n",
    "\n",
    "#this code creates an output directory in the parent director, if one does not exist yet\n",
    "#Note: sets where all of the output files will be written, since outputs files are large\n",
    "path = os.getcwd()\n",
    "parent = os.path.dirname(path)\n",
    "outputs_dir = parent+'\\outputs'\n",
    "if not os.path.exists(outputs_dir):\n",
    "    os.makedirs(outputs_dir)\n",
    "print('output files are written out in parent directory: '+outputs_dir)\n",
    "print()\n",
    "load_raw = pd.read_csv('inputs/load_duration_curves_raw_data.csv')\n",
    "print(load_raw.head(2))\n",
    "print()\n",
    "print('number of rows in dataset =', load_raw.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows in dataset (including CN) = 27010\n",
      "number of regions in dataset (including CN) = 74\n",
      "number of regional groups in dataset (including CN) = 10\n",
      "\n",
      "  R_Group R_Subgroup    Region  Month  Day    Hour 1    Hour 2    Hour 3  \\\n",
      "0     ERC       REST  ERC_REST      1    1   34,807    34,551    34,788    \n",
      "1     ERC       REST  ERC_REST      1    2   34,716    34,719    35,076    \n",
      "\n",
      "     Hour 4    Hour 5  ...   Hour 15   Hour 16   Hour 17   Hour 18   Hour 19  \\\n",
      "0   35,531    36,633   ...   38,507    40,084    41,198    40,959    40,549    \n",
      "1   35,891    37,091   ...   33,211    34,968    37,573    38,213    38,257    \n",
      "\n",
      "    Hour 20   Hour 21   Hour 22   Hour 23   Hour 24  \n",
      "0   39,766    38,510    37,012    35,811    35,061   \n",
      "1   37,911    36,743    35,379    34,598    34,444   \n",
      "\n",
      "[2 rows x 29 columns]\n",
      "\n",
      "number of rows in dataset after removing CN = 22995\n",
      "number of regions in dataset (excluding CN) = 63\n",
      "number of regional groups in dataset (excluding CN) = 9\n"
     ]
    }
   ],
   "source": [
    "#Organizing regional data\n",
    "\n",
    "#create temporary copy to make changes on\n",
    "load_org = load_raw.copy()\n",
    "print('number of rows in dataset (including CN) =',load_org.shape[0])\n",
    "\n",
    "#Regional IDs\n",
    "unique_r = pd.Series(load_org['Region'].unique()).dropna()\n",
    "rl = unique_r.str.split(\"_\",n=1,expand=True)\n",
    "rl[2] = unique_r\n",
    "#print(rl)\n",
    "print('number of regions in dataset (including CN) =',unique_r.shape[0])\n",
    "\n",
    "#Cleaning up the empty subgroups\n",
    "#print(rl[rl.isna().any(axis=1)])\n",
    "rl.loc[rl[0] == 'NENGREST', 1] = 'REST'\n",
    "rl.loc[rl[0] == 'FRCC', 1] = 'FRCC'\n",
    "\n",
    "#Cleaning up the misnamed groups\n",
    "#unique_g = pd.Series(rl[0].unique()).dropna()\n",
    "#print(unique_g)\n",
    "rl[0] = rl[0].replace('NENGREST','NENG')\n",
    "rl[0] = rl[0].replace('WECC','WEC')\n",
    "unique_g = pd.Series(rl[0].unique()).dropna()\n",
    "print('number of regional groups in dataset (including CN) =',unique_g.shape[0])\n",
    "rl.rename(columns={0 : \"R_Group\", 1: 'R_Subgroup', 2:'Region'},inplace=True)\n",
    "#print(rl.head())\n",
    "\n",
    "#Merging Regional Data to DF\n",
    "load_org = pd.merge(rl,load_org,on='Region',how='right')\n",
    "print()\n",
    "print(load_org.head(2))\n",
    "\n",
    "#Removing Canada\n",
    "load_org = load_org[load_org['R_Group']!=\"CN\"]\n",
    "print()\n",
    "print('number of rows in dataset after removing CN =',load_org.shape[0])\n",
    "unique_r = pd.Series(load_org['Region'].unique()).dropna()\n",
    "print('number of regions in dataset (excluding CN) =',unique_r.shape[0])\n",
    "unique_g = pd.Series(load_org['R_Group'].unique()).dropna()\n",
    "print('number of regional groups in dataset (excluding CN) =',unique_g.shape[0])\n",
    "\n",
    "#for testing only, otherwise comment out the lines below\n",
    "#NOTE: use FRCC for one region, ERC for two regions\n",
    "#load_org = load_org[load_org['R_Group']==\"FRCC\"]\n",
    "#print('number of rows in dataset for testing =',load_org.shape[0])\n",
    "#Organize temporal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Region R_Group R_Subgroup  Season  Month  Day  Hour  Load\n",
      "551878  WECC_WY     WEC         WY  winter     12  364    24  1791\n",
      "551879  WECC_WY     WEC         WY  winter     12  365    24  1834\n",
      "\n",
      "number of rows in dataset = 551880\n",
      "number of regs in dataset = 63.0\n"
     ]
    }
   ],
   "source": [
    "#rename hour titles to just the value ('Hour 1' --> 1)\n",
    "load_org.columns = load_org.columns.str.replace('Hour ', '')\n",
    "#print(load_org.head(2))\n",
    "\n",
    "#melt function converts values in wide format to long format\n",
    "load_dur = pd.melt(load_org,id_vars=['R_Group','R_Subgroup','Region','Month','Day'], \\\n",
    "                   var_name='Hour',value_name='Load')\n",
    "\n",
    "#print(load_dur.dtypes)\n",
    "\n",
    "#days are counted 1 to 365, not 1 to 31\n",
    "unique_d = pd.Series(load_dur['Day'].unique()).dropna()\n",
    "#print(unique_d.tail(2))\n",
    "\n",
    "#turn hour values to numeric \n",
    "load_dur['Hour'] = pd.to_numeric(load_dur['Hour'],errors='coerce')\n",
    "unique_h = pd.Series(load_dur['Hour'].unique()).dropna()\n",
    "#print(unique_h.tail(2))\n",
    "\n",
    "#turn load values to numeric \n",
    "load_dur['Load'] = pd.to_numeric(load_dur['Load'].str.replace(\",\",\"\"),errors='coerce')\n",
    "#print(load_dur.head(2))\n",
    "\n",
    "season_month = pd.read_csv('inputs/season_months.csv')\n",
    "load_dur = pd.merge(load_dur,season_month, on='Month', how='left')\n",
    "\n",
    "#organized long format data to new csv file\n",
    "load_dur = load_dur[['Region','R_Group','R_Subgroup','Season','Month','Day','Hour','Load']]\n",
    "load_dur.to_csv('../outputs/load_long_format.csv')\n",
    "print(load_dur.tail(2))\n",
    "print()\n",
    "print('number of rows in dataset =',load_dur.shape[0])\n",
    "print('number of regs in dataset =',load_dur.shape[0]/8760)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solar Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Region State  Resource Class  Month  Day  Season  1  2  3  4  ...   15  \\\n",
      "0  ERC_PHDL    TX               6      1    1  Winter  0  0  0  0  ...  516   \n",
      "1  ERC_PHDL    TX               6      1    2  Winter  0  0  0  0  ...  506   \n",
      "\n",
      "    16   17   18  19  20  21  22  23  24  \n",
      "0  548  537  238   0   0   0   0   0   0  \n",
      "1  547  539  244   0   0   0   0   0   0  \n",
      "\n",
      "[2 rows x 30 columns]\n",
      "\n",
      "number of rows in dataset = 58035\n"
     ]
    }
   ],
   "source": [
    "solar_raw = pd.read_csv('inputs/solar_generation.csv')\n",
    "print(solar_raw.head(2))\n",
    "print()\n",
    "print('number of rows in dataset =', solar_raw.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows in dataset (including CN) = 58035\n",
      "number of regions in dataset (including CN) = 71\n",
      "number of regional groups in dataset (including CN) = 10\n",
      "\n",
      "  R_Group R_Subgroup    Region State  Resource Class  Month  Day  Season  1  \\\n",
      "0     ERC       PHDL  ERC_PHDL    TX               6      1    1  Winter  0   \n",
      "1     ERC       PHDL  ERC_PHDL    TX               6      1    2  Winter  0   \n",
      "\n",
      "   2  ...   15   16   17   18  19  20  21  22  23  24  \n",
      "0  0  ...  516  548  537  238   0   0   0   0   0   0  \n",
      "1  0  ...  506  547  539  244   0   0   0   0   0   0  \n",
      "\n",
      "[2 rows x 32 columns]\n",
      "\n",
      "number of rows in dataset after removing CN = 55115\n",
      "number of regions in dataset (excluding CN) = 64\n",
      "number of regional groups in dataset (excluding CN) = 9\n"
     ]
    }
   ],
   "source": [
    "#Organizing regional data\n",
    "\n",
    "#create temporary copy to make changes on\n",
    "solar_org = solar_raw.copy()\n",
    "print('number of rows in dataset (including CN) =',solar_org.shape[0])\n",
    "\n",
    "#Regional IDs\n",
    "unique_r = pd.Series(solar_org['Region'].unique()).dropna()\n",
    "rl = unique_r.str.split(\"_\",n=1,expand=True)\n",
    "rl[2] = unique_r\n",
    "#print(rl)\n",
    "print('number of regions in dataset (including CN) =',unique_r.shape[0])\n",
    "\n",
    "#Cleaning up the empty subgroups\n",
    "#print(rl[rl.isna().any(axis=1)])\n",
    "rl.loc[rl[0] == 'NENGREST', 1] = 'REST'\n",
    "rl.loc[rl[0] == 'FRCC', 1] = 'FRCC'\n",
    "\n",
    "#Cleaning up the misnamed groups\n",
    "#unique_g = pd.Series(rl[0].unique()).dropna()\n",
    "#print(unique_g)\n",
    "rl[0] = rl[0].replace('NENGREST','NENG')\n",
    "rl[0] = rl[0].replace('WECC','WEC')\n",
    "unique_g = pd.Series(rl[0].unique()).dropna()\n",
    "print('number of regional groups in dataset (including CN) =',unique_g.shape[0])\n",
    "rl.rename(columns={0 : \"R_Group\", 1: 'R_Subgroup', 2:'Region'},inplace=True)\n",
    "#print(rl.head())\n",
    "\n",
    "#Merging Regional Data to DF\n",
    "solar_org = pd.merge(rl,solar_org,on='Region',how='right')\n",
    "print()\n",
    "print(solar_org.head(2))\n",
    "\n",
    "#Removing Canada\n",
    "solar_org = solar_org[solar_org['R_Group']!=\"CN\"]\n",
    "print()\n",
    "print('number of rows in dataset after removing CN =',solar_org.shape[0])\n",
    "unique_r = pd.Series(solar_org['Region'].unique()).dropna()\n",
    "print('number of regions in dataset (excluding CN) =',unique_r.shape[0])\n",
    "unique_g = pd.Series(solar_org['R_Group'].unique()).dropna()\n",
    "print('number of regional groups in dataset (excluding CN) =',unique_g.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       R_Group R_Subgroup    Region State  Month  Day  TRG  Hour  Solar_Gen  \\\n",
      "0          ERC       PHDL  ERC_PHDL    TX      1    1    6     1        0.0   \n",
      "365        ERC       PHDL  ERC_PHDL    TX      1    1    7     1        0.0   \n",
      "55115      ERC       PHDL  ERC_PHDL    TX      1    1    6     2        0.0   \n",
      "55480      ERC       PHDL  ERC_PHDL    TX      1    1    7     2        0.0   \n",
      "110230     ERC       PHDL  ERC_PHDL    TX      1    1    6     3        0.0   \n",
      "\n",
      "        Season  \n",
      "0       winter  \n",
      "365     winter  \n",
      "55115   winter  \n",
      "55480   winter  \n",
      "110230  winter  \n"
     ]
    }
   ],
   "source": [
    "#melt function converts values in wide format to long format\n",
    "solar_dur = pd.melt(solar_org,id_vars=['R_Group','R_Subgroup','Region','State', \\\n",
    "                                       'Season','Month','Day','Resource Class'], \\\n",
    "                    var_name='Hour',value_name='Solar_Gen')\n",
    "#print(solar_dur)\n",
    "#print(solar_dur.dtypes)\n",
    "\n",
    "#turn hour values to numeric \n",
    "solar_dur['Hour'] = pd.to_numeric(solar_dur['Hour'],errors='coerce')\n",
    "unique_h = pd.Series(solar_dur['Hour'].unique()).dropna()\n",
    "#print(unique_h.tail(2))\n",
    "\n",
    "#edit columns\n",
    "solar_dur = solar_dur.drop(columns={'Season'})\n",
    "solar_dur = solar_dur.rename(columns={'Resource Class':'TRG'})\n",
    "#print(solar_dur)\n",
    "\n",
    "#change generation value to capacity factor\n",
    "solar_dur['Solar_Gen']=solar_dur['Solar_Gen']/1000\n",
    "\n",
    "#create new seasons column\n",
    "season_month = pd.read_csv('inputs/season_months.csv')\n",
    "solar_dur = pd.merge(solar_dur,season_month, on='Month', how='left')\n",
    "solar_dur = solar_dur.sort_values(['Region','Month','Day'])\n",
    "print(solar_dur.head())\n",
    "#print(solar_dur.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter by TRG because too big otherwise \n",
    "solar3 = solar_dur.loc[solar_dur['TRG'] == 3].reset_index(drop=True)\n",
    "solar3 = solar3.rename(columns={'Solar_Gen':'TRG3'}).drop(columns={'TRG'})\n",
    "\n",
    "solar4 = solar_dur.loc[solar_dur['TRG'] == 4].reset_index(drop=True)\n",
    "solar4 = solar4.rename(columns={'Solar_Gen':'TRG4'}).drop(columns={'TRG'})\n",
    "\n",
    "solar5 = solar_dur.loc[solar_dur['TRG'] == 5].reset_index(drop=True)\n",
    "solar5 = solar5.rename(columns={'Solar_Gen':'TRG5'}).drop(columns={'TRG'})\n",
    "\n",
    "solar6 = solar_dur.loc[solar_dur['TRG'] == 6].reset_index(drop=True)\n",
    "solar6 = solar6.rename(columns={'Solar_Gen':'TRG6'}).drop(columns={'TRG'})\n",
    "\n",
    "solar7 = solar_dur.loc[solar_dur['TRG'] == 7].reset_index(drop=True)\n",
    "solar7 = solar7.rename(columns={'Solar_Gen':'TRG7'}).drop(columns={'TRG'})\n",
    "\n",
    "solar8 = solar_dur.loc[solar_dur['TRG'] == 8].reset_index(drop=True)\n",
    "solar8 = solar8.rename(columns={'Solar_Gen':'TRG8'}).drop(columns={'TRG'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Region R_Group R_Subgroup State  Month  Day  Hour  Season  TRG3  TRG4  \\\n",
      "0  ERC_PHDL     ERC       PHDL    TX      1    1     1  winter   NaN   NaN   \n",
      "1  ERC_PHDL     ERC       PHDL    TX      1    1     2  winter   NaN   NaN   \n",
      "2  ERC_PHDL     ERC       PHDL    TX      1    1     3  winter   NaN   NaN   \n",
      "3  ERC_PHDL     ERC       PHDL    TX      1    1     4  winter   NaN   NaN   \n",
      "4  ERC_PHDL     ERC       PHDL    TX      1    1     5  winter   NaN   NaN   \n",
      "\n",
      "   TRG5  TRG6  TRG7  TRG8  \n",
      "0   NaN   0.0   0.0   NaN  \n",
      "1   NaN   0.0   0.0   NaN  \n",
      "2   NaN   0.0   0.0   NaN  \n",
      "3   NaN   0.0   0.0   NaN  \n",
      "4   NaN   0.0   0.0   NaN  \n",
      "\n",
      "number of rows in dataset = 683280\n",
      "number of regs in dataset = 78.0\n"
     ]
    }
   ],
   "source": [
    "#create DF that only has the labels, easier to merge onto\n",
    "solar_labels = solar_dur[['Region','R_Group','R_Subgroup','State','Month','Day','Hour','Season']].copy()\n",
    "solar_labels = solar_labels.drop_duplicates(['Region','R_Group','R_Subgroup','State','Month','Day','Hour'])\n",
    "#print(solar_labels)\n",
    "\n",
    "solar_dur2 = pd.merge(solar_labels,solar3,on=['R_Group','R_Subgroup','Region','State','Month','Day','Hour','Season'],how='left')\n",
    "solar_dur2 = pd.merge(solar_dur2,solar4,on=['R_Group','R_Subgroup','Region','State','Month','Day','Hour','Season'],how='left')\n",
    "solar_dur2 = pd.merge(solar_dur2,solar5,on=['R_Group','R_Subgroup','Region','State','Month','Day','Hour','Season'],how='left')\n",
    "solar_dur2 = pd.merge(solar_dur2,solar6,on=['R_Group','R_Subgroup','Region','State','Month','Day','Hour','Season'],how='left')\n",
    "solar_dur2 = pd.merge(solar_dur2,solar7,on=['R_Group','R_Subgroup','Region','State','Month','Day','Hour','Season'],how='left')\n",
    "solar_dur2 = pd.merge(solar_dur2,solar8,on=['R_Group','R_Subgroup','Region','State','Month','Day','Hour','Season'],how='left')\n",
    "print(solar_dur2.head())\n",
    "print()\n",
    "print('number of rows in dataset =',solar_dur2.shape[0])\n",
    "print('number of regs in dataset =',solar_dur2.shape[0]/8760)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Region R_Group R_Subgroup State  Season  Month  Day  Hour  TRG3  TRG4  \\\n",
      "0  ERC_PHDL     ERC       PHDL    TX  winter      1    1     1   NaN   NaN   \n",
      "1  ERC_PHDL     ERC       PHDL    TX  winter      1    1     2   NaN   NaN   \n",
      "2  ERC_PHDL     ERC       PHDL    TX  winter      1    1     3   NaN   NaN   \n",
      "3  ERC_PHDL     ERC       PHDL    TX  winter      1    1     4   NaN   NaN   \n",
      "4  ERC_PHDL     ERC       PHDL    TX  winter      1    1     5   NaN   NaN   \n",
      "\n",
      "   TRG5  TRG6  TRG7  TRG8  \n",
      "0   NaN   0.0   0.0   NaN  \n",
      "1   NaN   0.0   0.0   NaN  \n",
      "2   NaN   0.0   0.0   NaN  \n",
      "3   NaN   0.0   0.0   NaN  \n",
      "4   NaN   0.0   0.0   NaN  \n",
      "number of rows in dataset = 683280\n",
      "number of regs in dataset = 78.0\n"
     ]
    }
   ],
   "source": [
    "#matches the month and day-of-month to the day-of-year (e.g.365) value\n",
    "days = pd.read_csv('inputs/days_365.csv')\n",
    "#print(days.head())\n",
    "solar_dur2.rename(columns={'Day':'DayofMo'}, inplace=True)\n",
    "#print(solar_dur2.head())\n",
    "solar_dur3 = pd.merge(days,solar_dur2,on=['Month','DayofMo'],how='right')\n",
    "#print(solar_dur3.head())\n",
    "\n",
    "#organized long format data to new csv file\n",
    "solar_dur3 = solar_dur3[['Region','R_Group','R_Subgroup','State','Season','Month','Day','Hour',\n",
    "                       'TRG3','TRG4','TRG5','TRG6','TRG7','TRG8']]\n",
    "solar_dur3.to_csv('../outputs/solar_long_format.csv')\n",
    "print(solar_dur3.head())\n",
    "print('number of rows in dataset =',solar_dur3.shape[0])\n",
    "print('number of regs in dataset =',solar_dur2.shape[0]/8760)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wind Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Region State  TRG  Month  Day    1    2    3    4    5  ...   15   16  \\\n",
      "0  ERC_PHDL    TX    1      1    1  758  784  720  680  647  ...  250  265   \n",
      "1  ERC_PHDL    TX    1      1    2  720  752  745  737  718  ...  384  401   \n",
      "\n",
      "    17   18   19   20   21   22   23   24  \n",
      "0  284  278  318  428  543  666  689  700  \n",
      "1  368  335  270  386  497  611  595  681  \n",
      "\n",
      "[2 rows x 29 columns]\n",
      "\n",
      "number of rows in dataset = 247105\n"
     ]
    }
   ],
   "source": [
    "wind_raw = pd.read_csv('inputs/onshore_wind_gen.csv')\n",
    "print(wind_raw.head(2))\n",
    "print()\n",
    "print('number of rows in dataset =', wind_raw.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows in dataset (including CN) = 247105\n",
      "number of regions in dataset (including CN) = 69\n",
      "number of regional groups in dataset (including CN) = 10\n",
      "\n",
      "  R_Group R_Subgroup    Region State  TRG  Month  Day    1    2    3  ...  \\\n",
      "0     ERC       PHDL  ERC_PHDL    TX    1      1    1  758  784  720  ...   \n",
      "1     ERC       PHDL  ERC_PHDL    TX    1      1    2  720  752  745  ...   \n",
      "\n",
      "    15   16   17   18   19   20   21   22   23   24  \n",
      "0  250  265  284  278  318  428  543  666  689  700  \n",
      "1  384  401  368  335  270  386  497  611  595  681  \n",
      "\n",
      "[2 rows x 31 columns]\n",
      "\n",
      "number of rows in dataset after removing CN = 226665\n",
      "number of regions in dataset (excluding CN) = 63\n",
      "number of regional groups in dataset (excluding CN) = 9\n"
     ]
    }
   ],
   "source": [
    "#Organizing regional data\n",
    "\n",
    "#create temporary copy to make changes on\n",
    "wind_org = wind_raw.copy()\n",
    "print('number of rows in dataset (including CN) =',wind_org.shape[0])\n",
    "\n",
    "#Regional IDs\n",
    "unique_r = pd.Series(wind_org['Region'].unique()).dropna()\n",
    "rl = unique_r.str.split(\"_\",n=1,expand=True)\n",
    "rl[2] = unique_r\n",
    "#print(rl)\n",
    "print('number of regions in dataset (including CN) =',unique_r.shape[0])\n",
    "\n",
    "#Cleaning up the empty subgroups\n",
    "#print(rl[rl.isna().any(axis=1)])\n",
    "rl.loc[rl[0] == 'NENGREST', 1] = 'REST'\n",
    "rl.loc[rl[0] == 'FRCC', 1] = 'FRCC'\n",
    "\n",
    "#Cleaning up the misnamed groups\n",
    "#unique_g = pd.Series(rl[0].unique()).dropna()\n",
    "#print(unique_g)\n",
    "rl[0] = rl[0].replace('NENGREST','NENG')\n",
    "rl[0] = rl[0].replace('WECC','WEC')\n",
    "unique_g = pd.Series(rl[0].unique()).dropna()\n",
    "print('number of regional groups in dataset (including CN) =',unique_g.shape[0])\n",
    "rl.rename(columns={0 : \"R_Group\", 1: 'R_Subgroup', 2:'Region'},inplace=True)\n",
    "#print(rl.head())\n",
    "\n",
    "#Merging Regional Data to DF\n",
    "wind_org = pd.merge(rl,wind_org,on='Region',how='right')\n",
    "print()\n",
    "print(wind_org.head(2))\n",
    "\n",
    "#Removing Canada\n",
    "wind_org = wind_org[wind_org['R_Group']!=\"CN\"]\n",
    "print()\n",
    "print('number of rows in dataset after removing CN =',wind_org.shape[0])\n",
    "unique_r = pd.Series(wind_org['Region'].unique()).dropna()\n",
    "print('number of regions in dataset (excluding CN) =',unique_r.shape[0])\n",
    "unique_g = pd.Series(wind_org['R_Group'].unique()).dropna()\n",
    "print('number of regional groups in dataset (excluding CN) =',unique_g.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  R_Group R_Subgroup    Region State  TRG  Month  Day    1    2    3  ...  \\\n",
      "0     ERC       PHDL  ERC_PHDL    TX    6      1    1  470  451  469  ...   \n",
      "1     ERC       PHDL  ERC_PHDL    TX    6      1    2  630  614  592  ...   \n",
      "2     ERC       PHDL  ERC_PHDL    TX    6      1    3  674  685  670  ...   \n",
      "3     ERC       PHDL  ERC_PHDL    TX    6      1    4  633  589  559  ...   \n",
      "4     ERC       PHDL  ERC_PHDL    TX    6      1    5  467  475  481  ...   \n",
      "\n",
      "    15   16   17   18   19   20   21   22   23   24  \n",
      "0  410  469  490  475  474  479  484  525  585  611  \n",
      "1  278  316  340  364  320  354  384  489  579  631  \n",
      "2  472  464  448  422  439  512  560  630  661  646  \n",
      "3  188  208  216  196  200  233  284  403  430  444  \n",
      "4  263  286  289  298  270  281  310  386  377  394  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "#locate each TRG in the DF \n",
    "wind1 = wind_org.loc[wind_org['TRG'] == 1].reset_index(drop=True)\n",
    "wind2 = wind_org.loc[wind_org['TRG'] == 2].reset_index(drop=True)\n",
    "wind3 = wind_org.loc[wind_org['TRG'] == 3].reset_index(drop=True)\n",
    "wind4 = wind_org.loc[wind_org['TRG'] == 4].reset_index(drop=True)\n",
    "wind5 = wind_org.loc[wind_org['TRG'] == 5].reset_index(drop=True)\n",
    "wind6 = wind_org.loc[wind_org['TRG'] == 6].reset_index(drop=True)\n",
    "print(wind6.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melt each TRG invidually, then combine. Otherwise the file is too large. \n",
    "### TRG 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Region R_Group R_Subgroup State  Season  Month  Day  Hour   TRG1\n",
      "0      ERC_PHDL     ERC       PHDL    TX  winter      1    1     1  0.758\n",
      "18980  ERC_PHDL     ERC       PHDL    TX  winter      1    1     2  0.784\n",
      "37960  ERC_PHDL     ERC       PHDL    TX  winter      1    1     3  0.720\n",
      "56940  ERC_PHDL     ERC       PHDL    TX  winter      1    1     4  0.680\n",
      "75920  ERC_PHDL     ERC       PHDL    TX  winter      1    1     5  0.647\n",
      "\n",
      "number of rows in dataset = 455520\n"
     ]
    }
   ],
   "source": [
    "#melt function converts values in wide format to long format\n",
    "wind_dur1 = pd.melt(wind1,id_vars=['R_Group','R_Subgroup','Region','State','Month','Day','TRG'],\n",
    "                    var_name='Hour',value_name='Wind_Gen')\n",
    "wind_dur1['Wind_Gen']=wind_dur1['Wind_Gen']/1000\n",
    "#print(wind_dur1.head())\n",
    "#print(wind_dur1.dtypes)\n",
    "\n",
    "unique_d = pd.Series(wind_dur1['Day'].unique()).dropna()\n",
    "#print(unique_d.tail(2))\n",
    "\n",
    "#turn hour values to numeric \n",
    "wind_dur1['Hour'] = pd.to_numeric(wind_dur1['Hour'],errors='coerce')\n",
    "unique_h = pd.Series(wind_dur1['Hour'].unique()).dropna()\n",
    "#print(unique_h.tail(2))\n",
    "\n",
    "#create new seasons column\n",
    "season_month = pd.read_csv('inputs/season_months.csv')\n",
    "wind_dur1 = pd.merge(wind_dur1,season_month, on='Month', how='left')\n",
    "\n",
    "#edit columns \n",
    "wind_dur1 = wind_dur1.rename(columns={'Wind_Gen':'TRG1'}).drop(columns={'TRG'})\n",
    "wind_dur1 = wind_dur1[['Region','R_Group','R_Subgroup','State','Season','Month','Day','Hour','TRG1']]\n",
    "wind_dur1 = wind_dur1.sort_values(['Region','Month','Day'])\n",
    "print(wind_dur1.head())\n",
    "print()\n",
    "print('number of rows in dataset =',wind_dur1.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRG 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       R_Group R_Subgroup   Region State  Month  Day  Hour   TRG2  Season\n",
      "437998     WEC         WY  WECC_WY    WY     12   30    24  0.615  winter\n",
      "437999     WEC         WY  WECC_WY    WY     12   31    24  0.864  winter\n",
      "\n",
      "number of rows in dataset = 438000\n"
     ]
    }
   ],
   "source": [
    "#melt function converts values in wide format to long format\n",
    "wind_dur2 = pd.melt(wind2,id_vars=['R_Group','R_Subgroup','Region','State','Month','Day','TRG'],\n",
    "                    var_name='Hour',value_name='Wind_Gen')\n",
    "wind_dur2['Wind_Gen']=wind_dur2['Wind_Gen']/1000\n",
    "#print(wind_dur2)\n",
    "#print(wind_dur2.dtypes)\n",
    "\n",
    "#\n",
    "unique_d = pd.Series(wind_dur2['Day'].unique()).dropna()\n",
    "#print(unique_d.tail(2))\n",
    "\n",
    "#turn hour values to numeric \n",
    "wind_dur2['Hour'] = pd.to_numeric(wind_dur2['Hour'],errors='coerce')\n",
    "unique_h = pd.Series(wind_dur2['Hour'].unique()).dropna()\n",
    "#print(unique_h.tail(2))\n",
    "\n",
    "#create new seasons column\n",
    "season_month = pd.read_csv('inputs/season_months.csv')\n",
    "wind_dur2 = pd.merge(wind_dur2,season_month, on='Month', how='left')\n",
    "\n",
    "#edit columns \n",
    "wind_dur2 = wind_dur2.rename(columns={'Wind_Gen':'TRG2'}).drop(columns={'TRG'})\n",
    "print(wind_dur2.tail(2))\n",
    "print()\n",
    "print('number of rows in dataset =',wind_dur2.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRG 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       R_Group R_Subgroup   Region State  Month  Day  Hour   TRG3  Season\n",
      "508078     WEC         WY  WECC_WY    WY     12   30    24  0.657  winter\n",
      "508079     WEC         WY  WECC_WY    WY     12   31    24  0.883  winter\n",
      "\n",
      "number of rows in dataset = 508080\n"
     ]
    }
   ],
   "source": [
    "#melt function converts values in wide format to long format\n",
    "wind_dur3 = pd.melt(wind3,id_vars=['R_Group','R_Subgroup','Region','State','Month','Day','TRG'],\n",
    "                    var_name='Hour',value_name='Wind_Gen')\n",
    "wind_dur3['Wind_Gen']=wind_dur3['Wind_Gen']/1000\n",
    "#print(wind_dur3)\n",
    "#print(wind_dur3.dtypes)\n",
    "\n",
    "unique_d = pd.Series(wind_dur3['Day'].unique()).dropna()\n",
    "#print(unique_d.tail(2))\n",
    "\n",
    "#turn hour values to numeric \n",
    "wind_dur3['Hour'] = pd.to_numeric(wind_dur3['Hour'],errors='coerce')\n",
    "unique_h = pd.Series(wind_dur3['Hour'].unique()).dropna()\n",
    "#print(unique_h.tail(2))\n",
    "\n",
    "#create new seasons column\n",
    "season_month = pd.read_csv('inputs/season_months.csv')\n",
    "wind_dur3 = pd.merge(wind_dur3,season_month, on='Month', how='left')\n",
    "\n",
    "#edit columns \n",
    "wind_dur3 = wind_dur3.rename(columns={'Wind_Gen':'TRG3'}).drop(columns={'TRG'})\n",
    "print(wind_dur3.tail(2))\n",
    "print()\n",
    "print('number of rows in dataset =',wind_dur3.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRG 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       R_Group R_Subgroup   Region State  Month  Day  Hour   TRG4  Season\n",
      "578158     WEC         WY  WECC_WY    WY     12   30    24  0.672  winter\n",
      "578159     WEC         WY  WECC_WY    WY     12   31    24  0.880  winter\n",
      "\n",
      "number of rows in dataset = 578160\n"
     ]
    }
   ],
   "source": [
    "#melt function converts values in wide format to long format\n",
    "wind_dur4 = pd.melt(wind4,id_vars=['R_Group','R_Subgroup','Region','State','Month','Day','TRG'],\n",
    "                    var_name='Hour',value_name='Wind_Gen')\n",
    "wind_dur4['Wind_Gen']=wind_dur4['Wind_Gen']/1000\n",
    "#print(wind_dur4)\n",
    "#print(wind_dur4.dtypes)\n",
    "\n",
    "unique_d = pd.Series(wind_dur4['Day'].unique()).dropna()\n",
    "#print(unique_d.tail(2))\n",
    "\n",
    "#turn hour values to numeric \n",
    "wind_dur4['Hour'] = pd.to_numeric(wind_dur4['Hour'],errors='coerce')\n",
    "unique_h = pd.Series(wind_dur4['Hour'].unique()).dropna()\n",
    "#print(unique_h.tail(2))\n",
    "\n",
    "#create new seasons column\n",
    "season_month = pd.read_csv('inputs/season_months.csv')\n",
    "wind_dur4 = pd.merge(wind_dur4,season_month, on='Month', how='left')\n",
    "\n",
    "#edit columns \n",
    "wind_dur4 = wind_dur4.rename(columns={'Wind_Gen':'TRG4'}).drop(columns={'TRG'})\n",
    "print(wind_dur4.tail(2))\n",
    "print()\n",
    "print('number of rows in dataset =',wind_dur4.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRG 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       R_Group R_Subgroup   Region State  Month  Day  Hour   TRG5  Season\n",
      "727078     WEC         WY  WECC_WY    WY     12   30    24  0.637  winter\n",
      "727079     WEC         WY  WECC_WY    WY     12   31    24  0.792  winter\n",
      "\n",
      "number of rows in dataset = 727080\n"
     ]
    }
   ],
   "source": [
    "#melt function converts values in wide format to long format\n",
    "wind_dur5 = pd.melt(wind5,id_vars=['R_Group','R_Subgroup','Region','State','Month','Day','TRG'],\n",
    "                    var_name='Hour',value_name='Wind_Gen')\n",
    "wind_dur5['Wind_Gen']=wind_dur5['Wind_Gen']/1000\n",
    "#print(wind_dur5)\n",
    "#print(wind_dur5.dtypes)\n",
    "\n",
    "unique_d = pd.Series(wind_dur5['Day'].unique()).dropna()\n",
    "#print(unique_d.tail(2))\n",
    "\n",
    "#turn hour values to numeric \n",
    "wind_dur5['Hour'] = pd.to_numeric(wind_dur5['Hour'],errors='coerce')\n",
    "unique_h = pd.Series(wind_dur5['Hour'].unique()).dropna()\n",
    "#print(unique_h.tail(2))\n",
    "\n",
    "#create new seasons column\n",
    "season_month = pd.read_csv('inputs/season_months.csv')\n",
    "wind_dur5 = pd.merge(wind_dur5,season_month, on='Month', how='left')\n",
    "\n",
    "#edit columns \n",
    "wind_dur5 = wind_dur5.rename(columns={'Wind_Gen':'TRG5'}).drop(columns={'TRG'})\n",
    "print(wind_dur5.tail(2))\n",
    "print()\n",
    "print('number of rows in dataset =',wind_dur5.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRG 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       R_Group R_Subgroup   Region State  Month  Day  Hour   TRG6  Season\n",
      "832198     WEC         WY  WECC_WY    WY     12   30    24  0.505  winter\n",
      "832199     WEC         WY  WECC_WY    WY     12   31    24  0.605  winter\n",
      "\n",
      "number of rows in dataset = 832200\n"
     ]
    }
   ],
   "source": [
    "#melt function converts values in wide format to long format\n",
    "wind_dur6 = pd.melt(wind6,id_vars=['R_Group','R_Subgroup','Region','State','Month','Day','TRG'],\n",
    "                    var_name='Hour',value_name='Wind_Gen')\n",
    "wind_dur6['Wind_Gen']=wind_dur6['Wind_Gen']/1000\n",
    "#print(wind_dur6)\n",
    "#print(wind_dur6.dtypes)\n",
    "\n",
    "unique_d = pd.Series(wind_dur6['Day'].unique()).dropna()\n",
    "#print(unique_d.tail(2))\n",
    "\n",
    "#turn hour values to numeric \n",
    "wind_dur6['Hour'] = pd.to_numeric(wind_dur6['Hour'],errors='coerce')\n",
    "unique_h = pd.Series(wind_dur6['Hour'].unique()).dropna()\n",
    "#print(unique_h.tail(2))\n",
    "\n",
    "#create new seasons column\n",
    "season_month = pd.read_csv('inputs/season_months.csv')\n",
    "wind_dur6 = pd.merge(wind_dur6,season_month, on='Month', how='left')\n",
    "\n",
    "#edit columns \n",
    "wind_dur6 = wind_dur6.rename(columns={'Wind_Gen':'TRG6'}).drop(columns={'TRG'})\n",
    "print(wind_dur6.tail(2))\n",
    "print()\n",
    "print('number of rows in dataset =',wind_dur6.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Region R_Group R_Subgroup State  Season  Month  Day  Hour   TRG1   TRG2  \\\n",
      "0  ERC_PHDL     ERC       PHDL    TX  winter      1    1     1  0.758  0.788   \n",
      "1  ERC_PHDL     ERC       PHDL    TX  winter      1    1     2  0.784  0.785   \n",
      "2  ERC_PHDL     ERC       PHDL    TX  winter      1    1     3  0.720  0.719   \n",
      "3  ERC_PHDL     ERC       PHDL    TX  winter      1    1     4  0.680  0.695   \n",
      "4  ERC_PHDL     ERC       PHDL    TX  winter      1    1     5  0.647  0.728   \n",
      "\n",
      "    TRG3   TRG4   TRG5   TRG6  \n",
      "0  0.713  0.653  0.573  0.470  \n",
      "1  0.718  0.687  0.555  0.451  \n",
      "2  0.642  0.605  0.567  0.469  \n",
      "3  0.585  0.579  0.572  0.453  \n",
      "4  0.583  0.538  0.599  0.487  \n"
     ]
    }
   ],
   "source": [
    "#merge into one DF \n",
    "wind_dur = pd.merge(wind_dur1,wind_dur2,on=['Region','R_Group','R_Subgroup','State',\n",
    "                                            'Season','Month','Day','Hour'],how='outer')\n",
    "wind_dur = pd.merge(wind_dur,wind_dur3,on=['Region','R_Group','R_Subgroup','State',\n",
    "                                           'Season','Month','Day','Hour'], how='outer')\n",
    "wind_dur = pd.merge(wind_dur,wind_dur4,on=['Region','R_Group','R_Subgroup','State',\n",
    "                                           'Season','Month','Day','Hour'], how='outer')\n",
    "wind_dur = pd.merge(wind_dur,wind_dur5,on=['Region','R_Group','R_Subgroup','State',\n",
    "                                           'Season','Month','Day','Hour'], how='outer')\n",
    "wind_dur = pd.merge(wind_dur,wind_dur6,on=['Region','R_Group','R_Subgroup','State',\n",
    "                                           'Season','Month','Day','Hour'], how='outer')\n",
    "print(wind_dur.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Region R_Group R_Subgroup State  Season  Month  Day  Hour   TRG1   TRG2  \\\n",
      "0  ERC_PHDL     ERC       PHDL    TX  winter      1    1     1  0.758  0.788   \n",
      "1  ERC_PHDL     ERC       PHDL    TX  winter      1    1     2  0.784  0.785   \n",
      "2  ERC_PHDL     ERC       PHDL    TX  winter      1    1     3  0.720  0.719   \n",
      "3  ERC_PHDL     ERC       PHDL    TX  winter      1    1     4  0.680  0.695   \n",
      "4  ERC_PHDL     ERC       PHDL    TX  winter      1    1     5  0.647  0.728   \n",
      "\n",
      "    TRG3   TRG4   TRG5   TRG6  \n",
      "0  0.713  0.653  0.573  0.470  \n",
      "1  0.718  0.687  0.555  0.451  \n",
      "2  0.642  0.605  0.567  0.469  \n",
      "3  0.585  0.579  0.572  0.453  \n",
      "4  0.583  0.538  0.599  0.487  \n",
      "number of rows in dataset = 867240\n",
      "number of regs in dataset = 78.0\n"
     ]
    }
   ],
   "source": [
    "#matches the month and day-of-month to the day-of-year (e.g.365) value\n",
    "#print(days.head())\n",
    "wind_dur.rename(columns={'Day':'DayofMo'}, inplace=True)\n",
    "#print(wind_dur.head())\n",
    "wind_dur_fin = pd.merge(days,wind_dur,on=['Month','DayofMo'],how='right')\n",
    "#print(wind_dur_fin.head())\n",
    "\n",
    "#organized long format data to new csv file\n",
    "wind_dur_fin = wind_dur_fin[['Region','R_Group','R_Subgroup','State','Season','Month','Day','Hour',\\\n",
    "                             'TRG1','TRG2','TRG3','TRG4','TRG5','TRG6']]\n",
    "wind_dur_fin.to_csv('../outputs/wind_long_format.csv')\n",
    "print(wind_dur_fin.head())\n",
    "print('number of rows in dataset =',wind_dur_fin.shape[0])\n",
    "print('number of regs in dataset =',solar_dur2.shape[0]/8760)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
